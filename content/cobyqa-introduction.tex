%% contents/cobyqa-introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ a new \glsfmtlong{dfo} method}
\label{ch:cobyqa-introduction}

This chapter introduces a new \gls{dfo} method, named \gls{cobyqa}.
It is a derivative-free trust-region \gls{sqp} method designed to tackle nonlinearly constrained optimization problems that include equality and inequality constraints.
A particular feature of \gls{cobyqa} is that it visits only points that respect the bound constraints, if any.
This is useful because the objective functions of applications that admit bound constraints are often undefined when the bounds are violated.

\Cref{sec:cobyqa-statement} first formulates the problem to be tackled by \gls{cobyqa}.
\Cref{sec:cobyqa-main} then presents the general framework of \gls{cobyqa} and some important components.
\Cref{sec:simple-constraints} provides further details on the management of the bound and linear constraints.
Finally, \cref{sec:cobyqa-merit-penalty} exhibits the merit function employed by \gls{cobyqa} and the updates of its penalty parameter.
Details on the methods used by \gls{cobyqa} to solve its various subproblems will be provided in \cref{ch:cobyqa-subproblems}, and its Python implementation will be presented in \cref{ch:cobyqa-implementation}.

\section{Statement of the problem}
\label{sec:cobyqa-statement}

The problems we consider in this chapter are of the form
\begin{subequations}
    \label{eq:problem-cobyqa}
    \begin{align}
        \min_{\iter \in \R^n}   & \quad \obj(\iter) \label{eq:problem-cobyqa-obj}\\
        \text{s.t.}             & \quad \con{i}(\iter) \le 0, ~ i \in \iub, \label{eq:problem-cobyqa-ub}\\
                                & \quad \con{i}(\iter) = 0, ~ i \in \ieq, \label{eq:problem-cobyqa-eq}\\
                                & \quad \xl \le x \le \xu, \label{eq:problem-cobyqa-bd}
    \end{align}
\end{subequations}
where~$\obj$ and~$\con{i}$ represent the objective and constraint functions, with~$i \in \iub \cup \ieq$ and the sets of indices~$\iub$ and~$\ieq$ being finite and disjoint, but possibly empty.
The lower bounds~$\xl \in (\R \cup \set{-\infty})^n$ and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl < \xu$.
Note that the bound constraints~\cref{eq:problem-cobyqa-bd} are not included in the inequality constraints~\cref{eq:problem-cobyqa-ub}, because they will be handled separately, as detailed in \cref{sec:simple-constraints}.

We will develop a derivative-free trust-region \gls{sqp} method for the problem~\cref{eq:problem-cobyqa}.
The method, named \gls{cobyqa} after \emph{\glsdesc{cobyqa}}, does not use derivatives of the objective function or the nonlinear constraint functions, but models them using underdetermined interpolation based on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).
This chapter presents the framework of the method, while the subproblems and the Python implementation will be discussed in \cref{ch:cobyqa-subproblems,ch:cobyqa-implementation}, respectively.

\section{The derivative-free trust-region \glsfmtshort{sqp} method}
\label{sec:cobyqa-main}

\index{COBYQA@\glsfmttext{cobyqa}|(}We presented in \cref{ch:sqp} the basic trust-region \gls{sqp} method.
We now adapt this framework to derivative-free settings.

\subsection{Interpolation-based quadratic models}
\label{subsec:interpolation-based-quadratic-models}

Recall that the basic trust-region \gls{sqp} method presented in \cref{alg:trust-region-sqp} models the objective and constraint functions based on their gradients and Hessian matrices.
Since we do not have access to such information, we use interpolation-based quadratic models of these functions.
Specifically, we use quadratic models obtained by underdetermined interpolation based on the derivative-free symmetric Broyden update, detailed in \cref{subsec:symmetric-broyden-updates}.

At the~$k$th iteration, we denote by~$\objm[k]$ the quadratic model of~$\obj$, and by~$\conm[k]{i}$ the quadratic model of~$\con{i}$, for all~$i \in \iub \cup \ieq$.
These models are built on an interpolation set~$\xpt[k] \subseteq \R^n$, which is maintained by the method and updated along the iterations.
It changes at most one point of~$\xpt[k]$ at each iteration, and ensures that~$\iter[k] \in \xpt[k]$, where~$\iter[k] \in \R^n$ denotes the~$k$th iterate.

The initial models~$\objm[0]$ and~$\conm[0]{i}$, for~$i \in \iub \cup \ieq$, are built on the initial interpolation set~$\xpt[0] \subseteq \R^n$, defined as follows according to \citeauthor{Powell_2009}~\cite{Powell_2009}.
The user provides a number~$m$, satisfying
\begin{equation*}
    n + 2 \le m \le \frac{1}{2} (n + 1) (n + 2),
\end{equation*}
which will be the number interpolation points at each iteration.
We are also provided with an initial guess~$\iter[0] \in \R^n$ and an initial trust-region radius~$\rad[0] > 0$ that satisfies
\begin{equation*}
    \rad[0] \le \frac{1}{2} \min_{1 \le i \le n} (\xu_i - \xl_i),
\end{equation*}
so that~$\xu_i \ge \xl_i + 2 \rad[0]$ for all~$i \in \set{1, 2, \dots, n}$.
Further, to avoid conflicts between the bounds and the interpolation points,~$\iter[0]$ is modified so that each component of~$\iter[0]$ is either on a bound or keeps a distance of at least~$\rad[0]$ from the corresponding bounds, while being feasible.

The initial interpolation set~$\xpt[0] = \set{y^1, y^2, \dots, y^m}$ is constructed in the following way.
The first~$n + 1$ points of~$\xpt[0]$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0]                      && \quad \text{if~$i = 1$,}\\
    & \iter[0] + \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\xl_{i - 1} \le \iter[0]_{i - 1} < \xu_{i - 1}$,}\\
    & \iter[0] - \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\iter[0]_{i - 1} = \xu_{i - 1}$,}
\end{empheq}
and the following~$\min \set{n, m - n - 1}$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0] - \rad[0] e_{i - n - 1}  && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\xl_{i - n - 1} < \iter[0]_{i - n - 1} \le \xu_{i - n - 1}$,}\\
    & \iter[0] + 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xl_{i - n - 1}$,}\\
    & \iter[0] - 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xu_{i - n - 1}$,}
\end{empheq}
where~$e_i$ denotes the~$i$th standard coordinate vector of~$\R^n$, i.e., the~$i$th column of~$I_n$.
If~$m > 2n + 1$, for~$i \in \set{2n + 2, 2n + 3, \dots, m}$, we set
\begin{equation*}
    y^i \eqdef y^{p(i) + 1} + y^{q(i) + 1} - \iter[0],
\end{equation*}
where~$p$ and~$q$ are defined by
\begin{equation*}
    p(i) \eqdef i - n - 1 - n \kappa(i) \quad \text{with} \quad \kappa(i) \eqdef \floor[\bigg]{\frac{i - n - 2}{n}},
\end{equation*}
\nomenclature[Oe]{$\floor{\cdot}$}{Floor operator}%
and
\begin{empheq}[left={q(i) \eqdef \empheqlbrace}]{alignat*=2}
    & p(i) + \kappa(i)      && \quad \text{if~$p(i) + \kappa(i) \le n$,}\\
    & p(i) + \kappa(i) - n  && \quad \text{otherwise.}
\end{empheq}
We point out that if~$m \le 2n + 1$ and~$\xl < \iter[0] < \xu$, then the interpolation set~$\xpt[0]$ is essentially the interpolation set studied in \cref{sec:optimal-interpolation-set}, which focus on~$\rad[0] = 1$.
We have shown that this set is optimal for~$m = 2n + 1$, in a sense specified in \cref{sec:optimal-interpolation-set}.
Therefore, as Powell did, we take the value~$m = 2n + 1$ by default.

An advantage of choosing such an initial interpolation set is that the coefficients of the minimum-norm quadratic interpolation model can be directly evaluated.
See~\cite[\S~9]{Powell_2009} for the detailed calculations.

Once the initial models are constructed, they will be maintained by the derivative-free symmetric Broyden update, in the same way as \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.
See~\cite{Powell_2004b,Powell_2004c},~\cite[\S~4]{Powell_2006}, and~\cite[\S~4]{Powell_2009} for details.

\subsection{A derivative-free trust-region \glsfmtshort{sqp} framework}
\label{subsec:cobyqa-framework}

We now present the derivative-free trust-region \gls{sqp} framework employed by \gls{cobyqa}.
We denote for convenience by~$\lagm[k]$\nomenclature[Fh]{$\lagm$}{Quadratic model of~$\lag$} the Lagrangian function evaluated on the models, i.e.,
\begin{equation*}
    \lagm[k](\iter, \lm) \eqdef \objm[k](\iter) + \sum_{\mathclap{i \in \iub \cup \ieq}} \lm_i \conm[k]{i}(\iter), \quad \text{for~$\iter \in \R^n$ and~$\lm_i \in \R$, with~$i \in \iub \cup \ieq$.}
\end{equation*}
As in \cref{sec:sqp-trust-region}, the merit function we consider is the~$\ell_2$-merit function, defined for a given penalty parameter~$\gamma^k \ge 0$ by
\begin{equation*}
    \merit[k](\iter) \eqdef \obj(x) + \gamma^k \sqrt{\sum_{i \in \iub} \posp{\con{i}(\iter)}^2 + \sum_{i \in \ieq} \abs{\con{i}(\iter)}^2}, \quad \text{for~$\iter \in \R^n$.}
\end{equation*}
We denote by~$\meritm[k]$ the~$\ell_2$-merit function computed on the \gls{sqp} subproblem, i.e.,
\begin{equation}
    \label{eq:l2-merit-function-model}
    \meritm[k](\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma^k \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation}
where~$\Phi$ is defined by
\begin{equation}
    \label{eq:l2-merit-function-model-penalty}
    \Phi(d) \eqdef \sqrt{\sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2}.
\end{equation}
The framework is given in \cref{alg:derivative-free-trust-region-sqp}, which hides many details, including the definition of \enquote{convergence} in the loop, the calculation of~$\step[k]$, the update of~$\lm[k]$, the update of~$\rad[k]$, and the geometry improvement of the interpolation set, which will be specified in \cref{subsec:managing-trust-region-radius,subsec:solving-trust-region-subproblem,subsec:least-squares-lagrange-multipliers,subsec:managing-trust-region-radius,subsec:geometry-improvement}, respectively.

\begin{algorithm}
    \caption[Derivative-free trust-region \glsfmtshort{sqp} method]{Derivative-free trust-region \glsfmtshort{sqp} method\textsuperscript{$\dagger$}}
    \label{alg:derivative-free-trust-region-sqp}
    \DontPrintSemicolon
    \onehalfspacing
    \algorithmfootnote{\textsuperscript{$\dagger$}Recall that superscripts are iteration counters rather than exponents.}
    \KwData{Objective function~$f$, constraint functions~$\set{\con{i}}_{i \in \iub \cup \ieq}$, initial guess~$\iter[0] \in \R^n$, and initial trust-region radius~$\rad[0] > 0$.}
    Set the penalty parameter~$\gamma^{-1} \gets  0$\;
    Build the initial interpolation set~$\xpt[0] \subseteq \R^n$ described in \cref{subsec:interpolation-based-quadratic-models}\;
    Redefine~$x^0$ to a solution to~$\min_{y \in \xpt[0]} \obj(y)$\;
    Estimate the initial Lagrange multiplier~$\lm[0] = [\lm[0]_i]_{i \in \iub \cup \ieq}^{\T}$\; \nllabel{alg:derivative-free-trust-region-sqp-initial-multipliers}
    \For{$k = 0, 1, \dots$ until convergence}{
        Update~$\objm[k]$ and~$\conm[k]{i}$ for~$i \in \iub \cup \ieq$ as mentioned in \cref{subsec:interpolation-based-quadratic-models} \nllabel{alg:derivative-free-trust-region-sqp-models}\;
        Set the trial step~$\step[k] \in \R^n$ to an approximate solution to
        \begin{subequations}
            \label{eq:derivative-free-trust-region-sqp-subproblem}
            \begin{algomathalign}
                \min_{\step \in \R^n}   & \quad \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
                \text{s.t.}             & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step \le 0, ~ i \in \iub,\\
                                        & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                                        & \quad \xl \le \iter[k] + \step \le \xu,\\
                                        & \quad \norm{\step} \le \rad[k]
            \end{algomathalign}
        \end{subequations} \nllabel{alg:derivative-free-trust-region-sqp-subproblem}
        Pick a penalty parameter~$\gamma^k \ge \max @@ \set{\gamma^{k - 1}, \norm{\lm[k]}}$ providing~$\meritm[k](\step[k]) < \meritm[k](0)$ \nllabel{alg:derivative-free-trust-region-sqp-penalty}\;
        Evaluate the trust-region ratio
        \begin{algomathdisplay}
            \ratio[k] \gets \frac{\merit[k](\iter[k]) - \merit[k](\iter[k] + \step[k])}{\meritm[k](0) - \meritm[k](\step[k])}
        \end{algomathdisplay}
        \eIf{$\ratio[k] > 0$}{
            Choose a point~$\bar{y} \in \xpt[k]$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-1}
        }{
            Choose a point~$\bar{y} \in \xpt[k] \setminus \set{\iter[k]}$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-2}
        }
        Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k] \setminus \set{\bar{y}}) \cup \set{\iter[k] + \step[k]}$\;
        Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$\; \nllabel{alg:derivative-free-trust-region-sqp-iterate}
        Estimate the Lagrange multiplier~$\lm[k + 1] = [\lm[k + 1]_i]_{i \in \iub \cup \ieq}^{\T}$\; \nllabel{alg:derivative-free-trust-region-sqp-multipliers}
        Update the trust-region radius from~$\rad[k]$ to~$\rad[k + 1]$\; \label{alg:derivative-free-trust-region-sqp-radius}
        % \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
        %     & \theta_1 \rad[k],  && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
        %     & \rad[k],           && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
        %     & \theta_2 \rad[k],  && \quad \text{otherwise}
        % \end{algoempheq} \label{alg:derivative-free-trust-region-sqp-radius}
        Improve the geometry of~$\xpt[k + 1]$ if necessary\; \label{alg:derivative-free-trust-region-sqp-geometry}
    }
\end{algorithm}

In the implementation of \cref{alg:derivative-free-trust-region-sqp-iterate} in \cref{alg:derivative-free-trust-region-sqp},~$\iter[k + 1]$ is always set to a best point in~$\xpt[k + 1]$ according to~$\merit[k]$, in the sense that it minimizes~$\merit[k]$ in~$\xpt[k + 1]$.
If~$\iter[k]$ turns out to be optimal in~$\xpt[k + 1]$ according to~$\merit[k]$, then we choose~$\iter[k + 1] = \iter[k]$, even if there are other optimal points.
Note however that we cannot naively set~$\iter[k + 1]$ to either~$\iter[k] + \step[k]$ if~$\ratio[k] > 0$, or~$\iter[k]$ otherwise.
This is because~$\iter[k]$ is a best point in~$\xpt[k]$ according to~$\merit[k - 1]$, but it may not be the best one according to~$\merit[k]$.

\subsection{Solving the trust-region \glsfmtshort{sqp} subproblem}
\label{subsec:solving-trust-region-subproblem}

To solve the trust-region \gls{sqp} subproblem~\cref{eq:derivative-free-trust-region-sqp-subproblem}, we employ the Byrd-Omojokun approach that we presented in \cref{subsec:composite-step-inequality}.
It first generates a normal step~$\nstep[k]$ as an approximate solution to
\begin{subequations}
    \label{eq:cobyqa-normal}
    \begin{align}
        \min_{\step \in \R^n}   & \quad \sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2 \label{eq:cobyqa-normal-obj}\\
        \text{s.t.}             & \quad \xl \le \iter[k] + \step \le \xu,\\
                                & \quad \norm{\step} \le \zeta \rad[k], \label{eq:cobyqa-normal-tr}
    \end{align}
\end{subequations}
for some~$\zeta \in (0, 1)$.
In the implementation, we choose~$\zeta = 0.8$.
If~$\iter[k]$ is feasible for the original problem~\cref{eq:problem-cobyqa}, we choose~$\nstep[k] = 0$.
Further, it generates a tangential step~$\tstep[k]$ by solving approximately
\begin{subequations}
    \label{eq:cobyqa-tangential-original}
    \begin{align}
        \min_{\step \in \R^n}   & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.}             & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max @@ \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub, \label{eq:cobyqa-tangential-original-ub}\\
                                & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                                & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                                & \quad \norm{\nstep[k] + \step} \le \rad[k],
    \end{align}
\end{subequations}
and then sets the composite step~$\step[k] = \nstep[k] + \tstep[k]$.
Details on the calculations of the tangential and normal steps are provided in \cref{sec:cobyqa-tangential,sec:cobyqa-normal}, respectively.

As mentioned in \cref{subsec:composite-step-inequality}, our Byrd-Omojokun approach is different from the one proposed in~\cite[\S~15.4.4]{Conn_Gould_Toint_2000}, which replaces the constraint~\cref{eq:cobyqa-tangential-original-ub} with
\begin{equation*}
    \nabla \conm[k]{i}(\iter[k])^{\T} \step \le 0, ~ i \in \iub.
\end{equation*}
Our approach provides evidently better performance in practice for \gls{cobyqa}, as is demonstrated by the numerical experiments in \cref{subsec:perf-byrd-omojokun}.

If we have~$\iub \cup \ieq = \emptyset$, we then necessarily have~$\nstep[k] = 0$ because our algorithm guarantees that~$\xl \le \iter[k] \le \xu$.
The tangential subproblem is then identical to the original subproblem~\cref{eq:derivative-free-trust-region-sqp-subproblem}.
In \gls{cobyqa}, such a subproblem is approximately solved using the \gls{tcg} method that \citeauthor{Powell_2009} employed in \gls{bobyqa}~\cite{Powell_2009}.

When~$\iub \cup \ieq \neq \emptyset$, the tangential subproblem~\cref{eq:cobyqa-tangential-original} is approximately solved using the \gls{tcg} method that \citeauthor{Powell_2015} designed for \gls{lincoa}~\cite{Powell_2015}.
This method requires that
\begin{enumerate}
    \item the origin~$d = 0$ is feasible, and
    \item the trust region is centered on the origin.
\end{enumerate}
The first requirement is satisfied by~\cref{eq:cobyqa-tangential-original}.
To meet the second one, following the work of~\cite[Eq.~(2.10)]{Lalee_Nocedal_Plantenga_1998} and~\cite[Eq.~(15.4.3)]{Conn_Gould_Toint_2000}, we can solve instead
\begin{subequations}
    \label{eq:cobyqa-tangential}
    \begin{align}
        \min_{\step \in \R^n}   & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.}             & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max @@ \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub, \label{eq:cobyqa-tangential-ub}\\
                                & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq, \label{eq:cobyqa-tangential-eq}\\
                                & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                                & \quad \norm{\step} \le \sqrt{(\rad[k])^2 - \norm{\nstep[k]}^2}, \label{eq:cobyqa-tangential-tr}
    \end{align}
\end{subequations}
the only difference with~\cref{eq:cobyqa-tangential-original} being the trust-region constraint~\cref{eq:cobyqa-tangential-tr}.
In doing so, we would have
\begin{equation*}
    \norm{\step[k]} = \norm{\nstep[k] + \tstep[k]} \le \max_{d \in \R^n} @@ \set[\Big]{\norm{d} + \sqrt{(\rad[k])^2 - \norm{\step}^2} : \norm{d} \le \rad[k]} = \sqrt{2} \rad[k].
\end{equation*}
Therefore, to maintain the property~$\norm{\step[k]} \le \rad[k]$, we replace~$\rad[k]$ in the constraints~\cref{eq:cobyqa-normal-tr,eq:cobyqa-tangential-tr} with~$\rad[k] / \sqrt{2}$.

\subsection{Estimating the Lagrange multiplier}
\label{subsec:least-squares-lagrange-multipliers}

We now introduce the strategy employed by \gls{cobyqa} to estimate the Lagrange multiplier on \cref{alg:derivative-free-trust-region-sqp-multipliers} of \cref{alg:derivative-free-trust-region-sqp}.

Similar to~\cite[\S~15.2, p.~626]{Conn_Gould_Toint_2000} and~\cite[Eq.~(18.22)]{Nocedal_Wright_2006}, we let~$\lm[k + 1]$ be a \emph{least-squares Lagrange multiplier} (see also~\cite[\S~3.3]{Dussault_1995}), i.e., a solution to
\begin{subequations}
    \label{eq:least-squares-lagrange-multipliers-cobyqa}
    \begin{align}
        \min_{\lm}  & \quad \norm[\bigg]{\nabla \objm[k](\iter[k]) + \sum_{i \in \iub \cup \ieq} \lm_i \nabla \conm[k]{i}(\iter[k])}\\
        \text{s.t.} & \quad \lm_i = 0, ~ i \in \set{j \in \iub : \conm[k]{j}(\iter[k]) < 0} \label{eq:least-squares-lagrange-multipliers-cobyqa-complementary-slackness}\\
                    & \quad \lm_i \ge 0, ~ i \in \iub,
    \end{align}
\end{subequations}
where~$\lm = [\lm_i]_{i \in \iub \cup \ieq}^{\T}$.
Note that for all~$i \in \iub$,~$\conm[k]{i}(\iter[k]) = \con{i}(\iter[k])$, because~$\conm[k]{i}$ interpolates~$\con{i}$ on~$\xpt[k]$ and~$\iter[k] \in \xpt[k]$.
The conditions~\cref{eq:least-squares-lagrange-multipliers-cobyqa-complementary-slackness} correspond to the complementary slackness conditions of the inactive constraints at~$\iter[k]$.
Even though the complementary slackness conditions at the solution are~$\lm[\ast]_i \con{i}(\iter[\ast]) = 0$ for~$i \in \iub$, it is unreasonable to force~$\lm_i^{k + 1} = 0$ if~$\con{i}(\iter[k]) > 0$ and~$i \in \iub$, because the corresponding constraint is currently active.
Details on the calculations of the least-squares Lagrange multiplier are provided in \cref{sec:cobyqa-lagrange-multipliers}.

The initial Lagrange multiplier~$\lm[0]$ on \cref{alg:derivative-free-trust-region-sqp-initial-multipliers} of \cref{alg:derivative-free-trust-region-sqp} is evaluated in a very similar fashion.
It is set to a solution to~\cref{eq:least-squares-lagrange-multipliers-cobyqa} with~$k = 0$, so that it equals~$\lm[1]$.

We also mention that the least-squares multiplier can be regarded as an approximation of the multiplier of the \gls{sqp} subproblem, known as the QP multiplier.
See~\cite[pp.~538--539]{Nocedal_Wright_2006} for more details.

\subsection{Managing the trust-region radius}
\label{subsec:managing-trust-region-radius}

We now detail the trust-region radius management strategy employed by \gls{cobyqa}, corresponding to~\cref{alg:derivative-free-trust-region-sqp-radius} of \cref{alg:derivative-free-trust-region-sqp}.
The strategy does not only maintain the trust-region radius~$\rad[k]$ but also a lower bound~$\radlb[k]$ of it.
This strategy is taken from \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}, which were briefly described in \cref{subsec:uobyqa,subsec:newuoa,subsec:bobyqa,subsec:lincoa}.

The update of~$\rad[k]$ is given in \cref{alg:update-trust-region-radius}, which is typical for trust-region methods, except that the lower bound~$\radlb[k]$ is imposed.
The idea behind~$\radlb[k]$ will be explained later.
The parameters chosen in \gls{cobyqa} are~$\eta_1 = 0.1$,~$\eta_2 = 0.7$,~$\theta_1 = 0.5$,~$\theta_2 = 1.4$,~$\theta_3 = \sqrt{2}$, and~$\theta_4 = 2$.
Note that it is crucial to ensure that~$\theta_2 < \theta_3$.
Otherwise, if~$\rad[k] = \radlb[k]$ and the trial step~$\step[k]$ performs very well (i.e.,~$\ratio[k] > \eta_2$), then the method would set~$\rad[k + 1] = \rad[k]$, but~$\rad[k + 1] > \rad[k]$ is expected if~$\norm{\step[k]}$ is close to~$\rad[k]$.

\begin{algorithm}
    \caption{Updating the trust-region radius}
    \label{alg:update-trust-region-radius}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Current lower bound on the trust-region radius~$\radlb[k] > 0$, current trust-region radius~$\rad[k] \ge \radlb[k]$, current trust-region ratio~$\ratio[k] \in \R$, current trial step~$\step[k] \in \R^n$, and parameters~$0 < \eta_1 \le \eta_2 < 1$, and~$0 < \theta_1 < 1 \le \theta_2 < \theta_3 < \theta_4$.}
    \KwResult{Updated trust-region radius~$\rad[k + 1]$.}
    Update the trust-region radius
    \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
        & \theta_1 \rad[k]                                                                      && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
        & \max @@ \set{\theta_1 \rad[k], \norm{\step[k]}}                                          && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
        & \min @@ \set{\theta_3 \rad[k], \max @@ \set{\theta_1 \rad[k], \theta_4 \norm{\step[k]}}}    && \quad \text{otherwise}
    \end{algoempheq}
    \If{$\rad[k + 1] \le \theta_2 \radlb[k]$}{
        $\rad[k + 1] \gets \radlb[k]$\;
    }
\end{algorithm}

The value of~$\radlb[k]$ can be regarded as an indicator of the \emph{resolution} of the algorithm at the current iteration.
If we do not impose~$\rad[k] \ge \radlb[k]$, the trust-region radius~$\rad[k]$ may be reduced to a value that is too small for the current precision of the algorithm, making the interpolation points concentrate too much.
The value of~$\radlb[k]$ is never increased and is decreased when the algorithm decides that the work for the current value of~$\radlb[k]$ is finished.
This is reflected in practice by
\begin{enumerate}
    \item the fact that~$\rad[k]$ reaches its lower bound~$\radlb[k]$,
    \item a poor performance of the trust-region trial step~$\step[k]$, and
    \item the fact that the interpolation points are all close enough to~$\iter[k + 1]$.
\end{enumerate}
More specifically, similar to Powell's solvers, \gls{cobyqa} reduces the value of~$\radlb[k]$ if
\begin{equation*}
    \radlb[k] = \rad[k], \quad \ratio[k] \le \eta_1, \quad \text{and} \quad \max_{y \in \xpt[k + 1]} @@ \norm{y  - \iter[k + 1]} \le 2 \radlb[k].
\end{equation*}
There is also another exceptional case where~$\radlb[k]$ is reduced, which will be detailed at the end of \cref{subsec:geometry-improvement}.
When \gls{cobyqa} decides to reduce~$\radlb[k]$, it invokes \cref{alg:reducing-lower-bound-trust-region-radius} to do so, with the parameters~$\eta_3 = 16$,~$\eta_4 = 250$, and~$\theta_5 = 0.1$.
\Cref{alg:reducing-lower-bound-trust-region-radius} and these parameters are adopted from \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.

\begin{algorithm}
    \caption{Reducing the lower bound on the trust-region radius}
    \label{alg:reducing-lower-bound-trust-region-radius}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Final trust-region radius~$\radlb[\infty] > 0$, current lower bound on the trust-region radius~$\radlb[k] \ge \radlb[\infty]$, updated trust-region radius~$\rad[k + 1] \ge \radlb[k]$, and parameters~$1 \le \eta_3 < \eta_4$ and~$0 < \theta_5 < 1$.}
    \KwResult{Reduced lower bound on trust-region radius~$\radlb[k + 1]$ and modified trust-region radius~$\rad[k + 1]$.}
    \eIf{$\radlb[k] = \radlb[\infty]$}{
        Terminate the optimization method\; \nllabel{alg:reducing-lower-bound-trust-region-radius-stop}
    }{
        Update the lower bound on the trust-region radius
        \begin{algoempheq}[left={\radlb[k + 1] \gets \empheqlbrace}]{alignat*=2}
            & \theta_5 \radlb[k]                && \quad \text{if~$\eta_4 < \radlb[k] / \radlb[\infty]$,}\\
            & \sqrt{\radlb[k] \radlb[\infty]}   && \quad \text{if~$\eta_3 < \radlb[k] / \radlb[\infty] \le \eta_4$,}\\
            & \radlb[\infty]                    && \quad \text{otherwise}
        \end{algoempheq}
        Update the trust-region radius~$\rad[k + 1] \gets \max @@ \set{\rad[k + 1], \radlb[k + 1]}$\;
    }
\end{algorithm}

If \cref{alg:reducing-lower-bound-trust-region-radius-stop} of \cref{alg:reducing-lower-bound-trust-region-radius} is reached, then the algorithm has finished the work for the smallest desired resolution, and hence, we stop the computations.
This is, in fact, the definition of \enquote{convergence} we mentioned in \cref{alg:derivative-free-trust-region-sqp}, which is also the stopping criterion used in Powell's solvers.

\subsection{Updating the interpolation set}

We now detail how \gls{cobyqa} updates the interpolation set~$\xpt[k]$.
To this end, we only need to detail the choice of~$\bar{y}$ in \cref{alg:derivative-free-trust-region-sqp-remove-1,alg:derivative-free-trust-region-sqp-remove-2} of \cref{alg:derivative-free-trust-region-sqp}.
Then,~$\xpt[k + 1]$ will be set to~$(\xpt[k] \setminus \set{\bar{y}}) \cup \set{\iter[k] + \step[k]}$.

Let us first consider the case~$\ratio[k] \ge 0$, so that~$\bar{y}$ is chosen from~$\xpt[k]$.
We denote by~$\bar{\iter}$ the closest point from~$\iter[k]$ that solves
\begin{equation*}
    \min_{y \in \xpt[k]} @@ \merit[k](y).
\end{equation*}
This point is not necessarily~$\iter[k]$, because~$\merit[k]$ may differ from~$\merit[k - 1]$ due to the update of the penalty parameter.
If several such points exist, we select any of them.
We then set~$\bar{y}$ to a solution to
\begin{equation}
    \label{eq:choice-point-to-remove-trust-region}
    \max_{y \in \xpt[k]} @@ \abs{\omega(y)} \norm{y - \bar{\iter}}^4,
\end{equation}
where~$\omega(y)$ is a scaling factor, detailed later.
The term~$\norm{y - \bar{\iter}}$ in~\cref{eq:choice-point-to-remove-trust-region} intends to set~$\bar{y}$ to a point far away from~$\bar{\iter}$, because the interpolation points must be reasonably close in order to achieve a good precision of the models.
To explain the scalar factor~$\omega(y)$, recall from \cref{subsec:implementation-symmetric-broyden-update} that the inverse of the coefficient matrix of the interpolation problem is maintained.
Whenever an interpolation point is replaced with a new one, this inverse will be updated by the formula detailed in~\cite[Eq.~(2.12)]{Powell_2004c}, which has a scalar denominator.
We set~$\omega(y)$ to this denominator corresponding to the replacement of~$y \in \xpt[k]$ with~$\iter[k] + \step[k]$.
This is because we want this denominator to be far away from zero to avoid numerical difficulties.
The choice of the formula~\cref{eq:choice-point-to-remove-trust-region} is taken from \gls{lincoa}, the most recent \gls{dfo} solver of \citeauthor{Powell_2015}.
He also made very similar choices for \gls{newuoa}~\cite[Eq.~(7.4)]{Powell_2006} and \gls{bobyqa}~\cite[Eq.~(6.1)]{Powell_2009}.

The strategy for the case~$\ratio[k] < 0$ is quite similar.
We set~$\bar{y}$ to a solution to
\begin{equation*}
    \max_{y \in \xpt[k] \setminus \set{\iter[k]}} @@ \abs{\omega(y)} \norm{y - \bar{\iter}}^4.
\end{equation*}
This case enforces~$\bar{y} \neq \iter[k]$ to avoid removing~$\iter[k]$ from~$\xpt[k]$, as this point is better than~$\iter[k] + \step[k]$ according to~$\merit[k - 1]$.

Theoretically, it is tempting to set~$\bar{y}$ to the point that optimizes the~$\Lambda$-poisedness (see \cref{subsec:symmetric-broyden-updates}) of~$\xpt[k + 1]$ in some set, say
\begin{equation}
    \label{eq:ball-lambda-poisedness}
    \set{x \in \R^n : \norm{x - \bar{\iter}} \le \radlb[k]}.
\end{equation}
This idea has, however, a major drawback: it is expensive to implement due to the definition of the~$\Lambda$-poisedness.
Hence, from a computational perspective, we decide not to employ this technique in \gls{cobyqa}.

\subsection{Improving the geometry of the interpolation set}
\label{subsec:geometry-improvement}

We now detail the geometry-improving procedure, corresponding to \cref{alg:derivative-free-trust-region-sqp-geometry} of \cref{alg:derivative-free-trust-region-sqp}.
As we mentioned in \cref{ch:interpolation}, the interpolation set has to be reasonably well-poised to ensure the accuracy of the interpolation models.
However, it is known that model-based \gls{dfo} methods tend to lose the poisedness of their interpolation set as the iterations progress.
To cope with this difficulty, such methods usually include a geometry-improving mechanism.
This topic is well studied. See, e.g.,~\cite{Conn_Scheinberg_Vicente_2008a,Conn_Scheinberg_Vicente_2008b,Fasano_Morales_Nocedal_2009,Scheinberg_Toint_2010}.

We adapt the geometry-improving strategies designed by \citeauthor{Powell_2009} for \gls{bobyqa}~\cite{Powell_2009} and \gls{lincoa}.
Briefly speaking, a point~$\bar{y} \in \xpt[k + 1]$ is chosen to be replaced with another one~$\iter[k + 1] + \rstep[k + 1]$, where~$\rstep[k + 1] \in \R^n$ is a \emph{model step} to improve the geometry of~$\xpt[k + 1]$.

First of all, the point~$\bar{y}$ is chosen to be a solution to
\begin{equation}
    \label{eq:choice-point-geometry-improving}
    \max_{y \in \xpt[k + 1]} \norm{y - \iter[k + 1]}.
\end{equation}
Further, similar to~\cite[Eq.~(6.6)]{Powell_2006}, the step~$\rstep[k + 1] \in \R^n$ should provide a large value of~$\abs{\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])}$, where~$\lagp[\bar{y}]$ denotes the minimum Frobenius norm Lagrange polynomials for~$\xpt[k + 1]$ associated with~$\bar{y}$ (see \cref{def:lagrange-polynomials-minimum-norm}).
The reason for taking such a step is as follows.
Recall that we need to update the inverse of the coefficient matrix of the interpolation problem to replace~$\bar{y}$ with~$\iter[k + 1] + \rstep[k + 1]$ in~$\xpt[k + 1]$.
As already mentioned, the updating formula has a scalar denominator.
This denominator is always lower bounded by~$\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])^2$ as shown in~\cite[Eq.~(6.5)]{Powell_2006}.
Therefore, by selecting a model step~$\rstep[k + 1]$ that provides a large value of~$\abs{\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])}$, we keep the denominator away from zero, avoiding numerical difficulties.
In \gls{cobyqa}, the model step~$\rstep[k + 1]$ is selected from two alternatives~$\rstep[k + 1]_B$ and~$\rstep[k + 1]_L$, detailed below.

The first step~$\rstep[k + 1]_B$, adopted from \gls{bobyqa}, is an approximate solution to
\begin{subequations}
    \label{eq:geometry-subproblem}
    \begin{align}
        \max_{\step \in \R^n}   & \quad \abs{\lagp[\bar{y}](\iter[k + 1] + \step)}\\
        \text{s.t.}             & \quad \xl \le \iter[k + 1] + \step \le \xu,\\
                                & \quad \norm{\step} \le \bar{\rad},
    \end{align}
\end{subequations}
where, as in \gls{lincoa}, we set~$\bar{\rad} = \max \set{\rad[k + 1] / 10, \radlb[k + 1]}$.
Note that the linearized constraints are not taken into account in this subproblem.
We will detail how to solve the subproblem~\cref{eq:geometry-subproblem} in \cref{sec:cobyqa-geometry-improving}.

The second step~$\rstep[k + 1]_L$, adopted from \gls{lincoa}, is defined as follows.
Let~$\mathcal{W}$ be some approximation of the active set of the linearized constraints at~$\iter[k + 1]$.
In \gls{cobyqa}, we set~$\mathcal{W}$ to be the working set returned by the active-set method that evaluates the tangential step~\cref{eq:cobyqa-tangential} (see \cref{sec:cobyqa-tangential} for details).
Then~$\rstep[k + 1]_L$ is a Cauchy step for~$\abs{\lagp[\bar{y}](\iter[k + 1] + \step)}$ in the null space of the linearized constraints in~$\mathcal{W}$ subject to~$\norm{\step} \le \bar{\rad}$.
In our experiments, considering this step turns out to be crucial for the performance of \gls{cobyqa}.

The selection between~$\rstep[k + 1]_B$ and~$\rstep[k + 1]_L$ is done as follows.
We set~$\rstep[k + 1]$ to~$\rstep[k + 1]_L$ if
\begin{enumerate}
    \item the point~$\iter[k + 1] + \rstep[k + 1]_L$ is feasible with respect to the linearized constraints and the bounds, and
    \item the denominator of the updating formula corresponding to~$\rstep[k + 1]_L$ is at least a tenth of the one corresponding to~$\rstep[k + 1]_B$ in absolute value.
\end{enumerate}
Otherwise, we set~$\rstep[k + 1]$ to~$\rstep[k + 1]_B$.
When checking the feasibility of~$\iter[k + 1] + \rstep[k + 1]_L$, we allow small infeasibility of the linearized constraints, to include a tolerance for contributions from computer rounding errors.

Now that the general framework of the geometry-improving phase is set up, we need to decide when to entertain such a mechanism.
It is triggered when
\begin{enumerate}
    \item the trust-region trial step~$\step[k]$ performed poorly, and
    \item some interpolation points are far away from~$\iter[k + 1]$.
\end{enumerate}
More specifically, \gls{cobyqa} modifies the interpolation set~$\xpt[k + 1]$ if
\begin{equation*}
    \ratio[k] \le \eta_1 \quad \text{and} \quad \max_{y \in \xpt[k + 1]} @@ \norm{y - \iter[k + 1]} > \max @@ \set{\rad[k + 1], 2 \radlb[k + 1]}.
\end{equation*}
When this condition holds, \gls{cobyqa} entertains the geometry-improving phase given in \cref{alg:geometry-improving}.

\begin{algorithm}
    \caption{Geometry-improving phase}
    \label{alg:geometry-improving}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Bounds~$\xl$ and~$\xu$, current interpolation set~$\xpt[k + 1] \subseteq \R^n$, current lower bound on the trust-region radius~$\radlb[k + 1]$, current trust-region radius~$\rad[k + 1]$, and current best point so far~$\iter[k + 1] \in \xpt[k + 1]$.}
    \KwResult{Updated interpolation set~$\xpt[k + 1]$ and updated iterate~$\iter[k + 1]$.}
    Set~$\bar{y}$ to be a solution to~\cref{eq:choice-point-geometry-improving}\;
    Compute the model step~$\rstep[k + 1] \in \R^n$\;
    Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k + 1] \setminus \set{\bar{y}}) \cup \set{\iter[k + 1] + \rstep[k + 1]}$\;
    Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$ \label{alg:geometry-improving-iterate}\;
\end{algorithm}

There is an exceptional case where we jump from \cref{alg:derivative-free-trust-region-sqp-subproblem} to \cref{alg:derivative-free-trust-region-sqp-geometry} in \cref{alg:derivative-free-trust-region-sqp}, after setting the values~$\gamma^k = \gamma^{k - 1}$,~$\xpt[k + 1] = \xpt[k]$,~$\iter[k + 1] = \iter[k]$, and~$\lm[k + 1] = \lm[k]$.
\Cref{alg:derivative-free-trust-region-sqp} omits this case for simplicity, and we detail it now.
This jump is done if the trust-region trial step~$\step[k]$ generated at \cref{alg:derivative-free-trust-region-sqp-subproblem} of \cref{alg:derivative-free-trust-region-sqp} is small compared to the current trust-region radius, more precisely, if~$\norm{\step[k]} < \rad[k] / 2$.
In this case, we first reduce~$\rad[k + 1]$ to~$\rad[k + 1] / 2$, setting it further to~$\radlb[k]$ if this reduced value is below~$\theta_2 \radlb[k]$.
We then invoke \cref{alg:geometry-improving} if
\begin{equation*}
    \max_{y \in \xpt[k + 1]} @@ \norm{y - \iter[k + 1]} \ge \rad[k + 1].
\end{equation*}
However, if~$\norm{\step[k]} < \rad[k] / 2$ has happened at five consecutive iterations, or~$\norm{\step[k]} < \rad[k] / 10$ at three consecutive iterations, then the geometry-improving phase is not invoked.
Instead, we decrease~$\radlb[k]$ by invoking \cref{alg:reducing-lower-bound-trust-region-radius}, and continue with the next trust-region iteration.
This mechanism has been developed by Powell in his solver \gls{lincoa}, and similar strategies exist in \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, and \gls{bobyqa}~\cite{Powell_2009}.

We also employ the following mechanism from \gls{newuoa}, which aims at improving the performance of the quadratic models.
We denote for convenience~$\objmalt[k]$ the least Frobenius norm model of~$\obj$ on~$\xpt[k]$.
When evaluating the models at \cref{alg:derivative-free-trust-region-sqp-models} of \cref{alg:derivative-free-trust-region-sqp}, if at three consecutive iterations we have
\begin{equation*}
    \rad[k - 1] = \radlb[k - 1], \quad \ratio[k - 1] \le \eta_5, \quad \text{and} \quad \norm{\nabla \objm[k](\iter[k])} \ge \nu \norm{\nabla \objmalt[k](\iter[k])},
\end{equation*}
with~$\eta_5 \in (0, 1)$ and~$\nu \ge 0$, then~$\objm[k]$ is replaced with~$\objmalt[k]$, and the models of the nonlinear constraints are also replaced with their least Frobenius norm counterparts.
We choose in \gls{cobyqa}~$\eta_5 = 0.01$ and~$\nu = 10$.
Since \gls{cobyqa} maintains the inverse of the coefficient matrix of the interpolation problem, the least Frobenius norm models are easy to evaluate.
See~\cref{subsec:implementation-symmetric-broyden-update} for details.
As will be demonstrated in \cref{subsec:alternative-models}, this procedure improves the performance of \gls{cobyqa}.

\section{Management of bound and linear constraints}
\label{sec:simple-constraints}

\Gls{cobyqa} accepts three types of constraints, namely bound, linear, and nonlinear constraints.
They are handled separately, for the following reasons.

First of all, bound constraints often represent inalienable physical or theoretical restrictions.
In many applications for which \gls{cobyqa} is designed, the objective function is not defined if the bound constraints are violated.
For example, see the parameter tuning problem given in \cref{subsec:tuning-nonlinear-optimization-methods}.
For this reason, we implement \gls{cobyqa} so that it visits only points that respect the bounds, as is also the case for the \gls{bobyqa} method, presented in \cref{subsec:bobyqa}.

The linear constraints are usually less restrictive.
In applications, the objective function is often well-defined even at points that violate linear constraints.
Therefore, we do not enforce \gls{cobyqa} to always respect the linear constraints.
However, when setting up a model~$\conm[k]{i}$ of a linear constraint~$\con{i}$, we take directly~$\conm[k]{i} = \con{i}$ instead of constructing~$\conm[k]{i}$ by interpolation.
In exact arithmetic, the derivative-free symmetric Broyden update described in \cref{subsec:symmetric-broyden-updates} automatically ensures that~$\conm[k]{i} = \con{i}$ if~$\con{i}$ is linear. 
However, setting~$\conm[k]{i} = \con{i}$ is obviously better, because it reduces the computational expense and avoid rounding errors of constructing these models.

\section{Merit function and update of the penalty parameter}
\label{sec:cobyqa-merit-penalty}

We now discuss the merit function we use in \gls{cobyqa}.
Recall that we decided to use the~$\ell_2$-merit function.
This is because the~$\ell_2$-merit function~$\meritm[k]$ computed on the \gls{sqp} subproblem, given in~\cref{eq:l2-merit-function-model}, satisfies \cref{prop:byrd-omojokun-penalty}.
In this proposition, we denote by~$\meritm_{\gamma}$ the~$\ell_2$-merit function evaluated on the \gls{sqp} subproblem, i.e.,
\begin{equation*}
    \meritm_{\gamma}(\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation*}
where~$\Phi$ is defined by~\cref{eq:l2-merit-function-model-penalty} and where~$\gamma$ is the corresponding penalty parameter.
The same as~$\meritm[k]$, we do not include the bound constraints in the definition of~$\meritm_{\gamma}$, because the points visited by \gls{cobyqa} always satisfy the bound constraints~\cref{eq:problem-cobyqa-bd}.

\begin{proposition}
    \label{prop:byrd-omojokun-penalty}
    Let~$\step[k] = \nstep[k] + \tstep[k]$ be a composite step generated by the Byrd-Omojokun approach.
    Assume that~$\nstep[k]$ satisfies either~$\Phi(\nstep[k]) < \Phi(0)$ or~$\nstep[k] = 0$, and that~$\tstep[k]$ satisfies
    \begin{equation}
        \label{eq:byrd-omojokun-tangential-assumption}
        \nabla \objm[k](\iter[k])^{\T} \tstep[k] + \frac{1}{2} (\tstep[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \tstep[k]  \le 0.
    \end{equation}
    Then there exists~$\bar{\gamma} \ge 0$ such that for all~$\gamma \ge \bar{\gamma}$, we have~$\meritm_{\gamma}(\step[k]) \le \meritm_{\gamma}(0)$.
    Moreover, the least possible such value is
    \begin{empheq}[left={\bar{\gamma} = \empheqlbrace}]{alignat*=2}
        & 0                                                                                                                                                                         && \quad \text{if~$\Phi(\step[k]) = \Phi(0)$,}\\
        & \posp[\bigg]{\frac{\nabla \objm[k](\iter[k])^{\T} \step[k] + (\step[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step[k] / 2}{\Phi(0) - \Phi(\step[k])}}  && \quad \text{otherwise.}
    \end{empheq}
\end{proposition}

\begin{proof}
    Since~$\tstep[k]$ satisfies~\cref{eq:cobyqa-tangential-ub,eq:cobyqa-tangential-eq}, we have~$\Phi(\nstep[k] + \tstep[k]) \le \Phi(\nstep[k])$ so that it is necessary that~$\Phi(\step[k]) \le \Phi(0)$.
    If~$\Phi(\step[k]) = \Phi(0)$, then~$\Phi(\nstep[k]) = \Phi(0)$ and hence,~$\nstep[k] = 0$.
    In such a case, the result is clear, because of~\cref{eq:byrd-omojokun-tangential-assumption}.
    Otherwise, if~$\Phi(\step[k]) < \Phi(0)$, the result is clear because~$\meritm_{\gamma}$ is linear with respect to~$\gamma$.
\end{proof}

The strategy of \gls{cobyqa} to set the penalty parameter at \cref{alg:derivative-free-trust-region-sqp-penalty} of \cref{alg:derivative-free-trust-region-sqp} is given in \cref{alg:increase-penalty}.
Note that this strategy imposes~$\gamma^k \ge \gamma^{k - 1}$.
However, in the implementation of \gls{cobyqa}, we do include a procedure that attempts to reduce~$\gamma^k$, preventing it from becoming large, and avoiding computational difficulties.
This procedure is not included in \cref{alg:derivative-free-trust-region-sqp} for simplicity, and is triggered whenever~$\radlb[k]$ is decreased, i.e., immediately after \cref{alg:reducing-lower-bound-trust-region-radius} is entertained.
\Cref{alg:reducting-penalty} presents this procedure.
For simplicity, we assume in this algorithm that~$\ieq = \emptyset$.
If~$\ieq \neq \emptyset$, \gls{cobyqa} will view each equality constraint as two inequality constraints when invoking \cref{alg:reducting-penalty}.
This procedure is the same as the one used by \citeauthor{Powell_1994} in his solver \gls{cobyla}~\cite{Powell_1994} for a similar purpose.

\begin{algorithm}
    \caption[Reducing the penalty parameter]{Reducing the penalty parameter\textsuperscript{$\ddagger$}}
    \label{alg:reducting-penalty}
    \DontPrintSemicolon
    \onehalfspacing
    \algorithmfootnote{\textsuperscript{$\ddagger$}We assume that~$\ieq = \emptyset$; otherwise, each equality constraint is viewed as two inequality constraints.}
    \KwData{Objective function~$f$, constraint functions~$\set{\con{i}}_{i \in \iub \cup \ieq}$, current interpolation set~$\xpt[k + 1] \subseteq \R^n$, and current penalty parameter~$\gamma^k \ge 0$.}
    \KwResult{Modified penalty parameter~$\gamma^k \ge 0$.}
    Set the indices of the \enquote{important} constraints
    \begin{algomathdisplay}
        \iub^{\ast} \eqdef \set[\big]{i \in \iub : \min_{y \in \xpt[k + 1]} @@ \con{i}(y) < \max_{y \in \xpt[k + 1]} @@ 2 \con{i}(y)}
    \end{algomathdisplay}
    \eIf{$\iub^{\ast} = \emptyset$}{
        Set~$\gamma^k \gets 0$\;
    }{
        Replace~$\gamma^k$ by
        \begin{algomathdisplaynumbered}
            \label{eq:reducting-penalty}
            \min @@ \set[\bigg]{\frac{\max_{y \in \xpt[k + 1]} @@ \obj(y) - \min_{y \in \xpt[k + 1]} @@ \obj(y)}{\min_{i \in \iub^{\ast}} @@ \{ \max_{y \in \xpt[k + 1]} @@ \con{i}(y) - \min_{y \in \xpt[k + 1]} @@ \negp{\con{i}(y)} \}}, \gamma^k}
        \end{algomathdisplaynumbered}
    }
\end{algorithm}
\nomenclature[Ob]{$\negp{\cdot}$}{Negative-part operator}%

The notation~$\negp{\cdot}$ in \cref{alg:reducting-penalty} means to take the negative part of a given number.
This update of~$\gamma^k$ is detailed in~\cite[Eq.~(12) and~(13)]{Powell_1994} and the discussion around.
The ratio in~\cref{eq:reducting-penalty} can be understood as follows.
Its numerator corresponds to a typical change in the objective function, while the denominator's term
\begin{equation*}
    \max_{y \in \xpt[k + 1]} @@ \con{i}(y) - \min_{y \in \xpt[k + 1]} @@ \negp{\con{i}(y)}
\end{equation*}
represents a typical change in the~$i$th constraint if~$\min_{y \in \xpt[k + 1]} \con{i}(y) \le 0$, and some distance to feasibility otherwise.
See~\cite[\S~4]{Powell_1994} for more discussions about~\cref{eq:reducting-penalty}.\index{COBYQA@\glsfmttext{cobyqa}|)}

\section{Summary and remarks}

In this chapter, we presented the general framework of our new model-based \gls{dfo} method, named \gls{cobyqa}, and highlighted several important ingredients.

In a nutshell, \gls{cobyqa} is a \gls{dfo} trust-region \gls{sqp} method.
It builds quadratic models of the objective and constraint functions using the derivative-free symmetric Broyden update, estimates its Lagrange multiplier by the least-squares Lagrange multiplier, and solves its trust-region \gls{sqp} subproblem with a Byrd-Omojokun approach.
It uses an~$\ell_2$-merit function to assess the quality of each trial step.

\Gls{cobyqa} updates its trust-region radius in a way that is typical for trust-region methods, except that an adaptive lower bound is imposed on the trust-region radius.
Being updated along the iterations, this lower bound is used as an indicator of the current resolution of the algorithm, and prevents the trust-region radius from becoming too small compared to the resolution.
\Gls{cobyqa} never increases this lower bound, and decreases it if the algorithm decides that the work for the current resolution is finished.
This strategy is adopted from Powell's \gls{dfo} solvers.

Recall that model-based \gls{dfo} methods usually entertain a geometry-improving procedure, because they tend to lose the poisedness of their interpolation set as the iterations progress.
The geometry improvement of \gls{cobyqa} excludes from the interpolation set the furthest point from the current iterate, and includes a point that maximizes the Lagrange polynomial associated with the excluded point.
This is adopted from~\cite{Powell_2006,Powell_2009}.
The objective of this procedure is to improve the conditioning of the interpolation system.
As a consequence, the geometry improvement also makes the interpolation problem numerically more stable.

An important feature of \gls{cobyqa} is that it never attempts to visit points lying outside of the bounds.
All interpolation points and trial points always respect the bounds.
The motivation for us to design \gls{cobyqa} in this way is that, in many applications, the objective function is undefined when the bound constraints are violated.

Finally, we note that there exists another derivate-free trust-region \gls{sqp} method, named \gls{sqpdfo}~\cite{Troltzsch_2016,Gratton_Toint_Troltzsch_2011,Troltzsch_Ilic_Siggel_2021}.
This method reformulates the inequality constraints using slack variables, so that the reformulated problem has only equality constraints and bound constraints.
This increases the dimension of the problem, which may lead to inefficiency, especially if the amount of inequality constraints is large.
\Gls{cobyqa} does not have this problem because it handles the inequality constraints directly, without introducing slack variables.
Moreover, the current (August 2022) publicly available implementation of \gls{sqpdfo}\footnote{See \url{https://github.com/DLR-SC/sqpdfo}.} does not always respect the bound constraints, particularly during the geometry-improving phase.
In contrast, as mentioned above, \gls{cobyqa} always respects the bounds, which is crucial for many engineering and industrial applications (see \cref{sec:simple-constraints}).
