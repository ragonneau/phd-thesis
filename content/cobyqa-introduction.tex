%% contents/cobyqa-introduction.tex
%% Copyright 2021-2022 Tom M. Ragonneau
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Tom M. Ragonneau.
\chapter{\glsfmttext{cobyqa} \textemdash\ a new \glsfmtlong{dfo} method}
\label{ch:cobyqa-introduction}

\section{Statement of the problem}

In this chapter, we introduce a new model-based \gls{dfo} method for solving nonlinearly-constrained problems of the form
\begin{subequations}
    \label{eq:problem-cobyqa}
    \begin{align}
        \min        & \quad \obj(\iter) \label{eq:problem-cobyqa-obj}\\
        \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub, \label{eq:problem-cobyqa-ub}\\
                    & \quad \con{i}(\iter) = 0, ~ i \in \ieq, \label{eq:problem-cobyqa-eq}\\
                    & \quad \xl \le x \le \xu, \label{eq:problem-cobyqa-bd}\\
                    & \quad \iter \in \R^n, \nonumber
    \end{align}
\end{subequations}
where~$\obj$ and~$\con{i}$ represent the objective and constraint functions, with~$i \in \iub \cup \ieq$ and the sets of indices~$\iub$ and~$\ieq$ being finite and disjoint, but possibly empty.
The lower bounds~$\xl \in (\R \cup \set{-\infty})^n$ and the upper bounds~$\xu \in (\R \cup \set{\infty})^n$ satisfy~$\xl < \xu$.
Note that the bound constraints~\cref{eq:problem-cobyqa-bd} are not included in the inequality constraints~\cref{eq:problem-cobyqa-ub}, because they will be handled separately, as detailed in \cref{sec:simple-constraints}.

We will develop a derivative-free trust-region \gls{sqp} method for the problem~\cref{eq:problem-cobyqa}.
The method, named~\gls{cobyqa} after \emph{\glsdesc{cobyqa}}, does not use derivatives of the objective function or the nonlinear constraint functions, but models them using underdetermined interpolation based on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).
This chapter presents the framework of the method, while the subproblems and the Python implementation will be discussed in \cref{ch:cobyqa-subproblems,ch:cobyqa-implementation}, respectively.

\section{The derivative-free trust-region \glsfmtshort{sqp} method}

We presented in \cref{ch:sqp} the basic trust-region \gls{sqp} method.
We now adapt this framework to derivative-free settings.

\subsection{Interpolation-based quadratic models}
\label{subsec:interpolation-based-quadratic-models}

Recall that the basic trust-region \gls{sqp} method presented in \cref{alg:trust-region-sqp} models the objective and constraint functions based on their gradients and Hessian matrices.
Since we do not have access to such information, we use interpolation-based quadratic models of these functions.
To be specific, we use quadratic models obtained by underdetermined interpolation based on the derivative-free symmetric Broyden update, detailed in \cref{subsec:symmetric-broyden-updates}.

At the~$k$th iteration, we denote by~$\objm[k]$ the quadratic model of~$\obj$, and by~$\conm[k]{i}$ the quadratic model of~$\con{i}$, for all~$i \in \iub \cup \ieq$.
These models are built on an interpolation set~$\xpt[k] \subseteq \R^n$, which is maintained by the method and updated along the iterations.
It changes at most one point of~$\xpt[k]$ at each iteration, and ensures that~$\iter[k] \in \xpt[k]$, where~$\iter[k] \in \R^n$ denotes the~$k$th iterate.
% Inspired by the performances of the solvers \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa} of Powell, we decide to base our models~$\objm[k]$ and~$\conm[k]{i}$, for~$i \in \iub \cup \ieq$, on the derivative-free symmetric Broyden update (see \cref{subsec:symmetric-broyden-updates}).

The initial models~$\objm[0]$ and~$\conm[0]{i}$, for~$i \in \iub \cup \ieq$, are built on the initial interpolation set~$\xpt[0] \subseteq \R^n$, defined as follows according to \citeauthor{Powell_2009}~\cite{Powell_2009}.
The user provides a number~$m$, satisfying
\begin{equation*}
    n + 2 \le m \le \frac{1}{2} (n + 1) (n + 2),
\end{equation*}
which will be the number interpolation points at each iteration.
We are also provided with an initial guess~$\iter[0] \in \R^n$ satisfying~$\xl \le \iter[0] \le \xu$ and an initial trust-region radius~$\rad[0] > 0$ that satisfies
\begin{equation*}
    \rad[0] \le \frac{1}{2} \min_{1 \le i \le n} (\xu_i - \xl_i),
\end{equation*}
so that~$\xu_i \ge \xl_i + 2 \rad[0]$ for all~$i \in \set{1, 2, \dots, n}$.
Further, to avoid conflicts between the bounds and the interpolation points,~$\iter[0]$ is modified so that each component of~$\iter[0]$ is either on a bound or keeps a distance of at least~$\rad[0]$ from the corresponding bounds.

The initial interpolation set~$\xpt[0] = \set{y^1, y^2, \dots, y^m}$ is constructed in the following way.
The first~$n + 1$ points of~$\xpt[0]$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0]                      && \quad \text{if~$i = 1$,}\\
    & \iter[0] + \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\xl_{i - 1} \le \iter[0]_{i - 1} < \xu_{i - 1}$,}\\
    & \iter[0] - \rad[0] e_{i - 1}  && \quad \text{if~$2 \le i \le n + 1$ and~$\iter[0]_{i - 1} = \xu_{i - 1}$,}
\end{empheq}
and the following~$\min \set{n, m - n - 1}$ are defined by
\begin{empheq}[left={y^i \eqdef \empheqlbrace}]{alignat*=2}
    & \iter[0] - \rad[0] e_{i - n - 1}  && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\xl_{i - n - 1} < \iter[0]_{i - n - 1} \le \xu_{i - n - 1}$,}\\
    & \iter[0] + 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xl_{i - n - 1}$,}\\
    & \iter[0] - 2\rad[0] e_{i - n - 1} && \quad \text{if~$n + 2 \le i \le \min \set{2n + 1, m}$ and~$\iter[0]_{i - n - 1} = \xu_{i - n - 1}$,}
\end{empheq}
where~$e_i$ denotes the~$i$th standard coordinate vector of~$\R^n$, i.e., the~$i$th column of~$I_n$.
If~$m > 2n + 1$, for~$i \in \set{2n + 2, 2n + 3, \dots, m}$, we set
\begin{equation*}
    y^i \eqdef y^{p(i) + 1} + y^{q(i) + 1} - \iter[0],
\end{equation*}
where~$p$ and~$q$ are defined by
\begin{equation*}
    p(i) \eqdef i - n - 1 - n \kappa(i) \quad \text{with} \quad \kappa(i) \eqdef \floor[\bigg]{\frac{i - n - 2}{n}},
\end{equation*}
\nomenclature[Oe]{$\floor{\cdot}$}{Floor operator}%
and
\begin{empheq}[left={q(i) \eqdef \empheqlbrace}]{alignat*=2}
    & p(i) + \kappa(i)      && \quad \text{if~$p(i) + \kappa(i) \le n$,}\\
    & p(i) + \kappa(i) - n  && \quad \text{otherwise.}
\end{empheq}
We point out that if~$m \le 2n + 1$ and~$\xl < \iter[0] < \xu$, then the interpolation set~$\xpt[0]$ is essentially the interpolation set studied in \cref{sec:optimal-interpolation-set}, which focus on~$\rad[0] = 1$.
We have shown that this set is optimal for~$m = 2n + 1$, in a sense specified in \cref{sec:optimal-interpolation-set}.
Therefore, as Powell did, we take the value~$m = 2n + 1$ by default.

An advantage of choosing such an initial interpolation set is that the coefficients of the minimum-norm quadratic interpolation model can be directly evaluated.
See~\cite[\S~9]{Powell_2009} for the detailed calculations.

Once the initial models are constructed, they will be maintained by the derivative-free symmetric Broyden update, in the same way as \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.
See~\cite{Powell_2004b,Powell_2004c},~\cite[\S~4]{Powell_2006}, and~\cite[\S~4]{Powell_2009} for details.

\subsection{A derivative-free trust-region \glsfmtshort{sqp} framework}

We present in this section the derivative-free trust-region \gls{sqp} framework employed by \gls{cobyqa}.
We denote for convenience by~$\lagm[k]$\nomenclature[Fh]{$\lagm$}{Quadratic model of~$\lag$} the Lagrangian function evaluated on the models, i.e.,
\begin{equation*}
    \lagm[k](\iter, \lm) \eqdef \objm[k](\iter) + \sum_{\mathclap{i \in \iub \cup \ieq}} \lm_i \conm[k]{i}(\iter), \quad \text{for~$\iter \in \R^n$ and~$\lm_i \in \R$, with~$i \in \iub \cup \ieq$.}
\end{equation*}
As in \cref{sec:sqp-trust-region}, the merit function we consider is the~$\ell_2$-merit function, defined for a given penalty parameter~$\gamma^k \ge 0$ by
\begin{equation*}
    \merit[k](\iter) \eqdef \obj(x) + \gamma^k \sqrt{\sum_{i \in \iub} \posp{\con{i}(\iter)}^2 + \sum_{i \in \ieq} \abs{\con{i}(\iter)}^2}, \quad \text{for~$\iter \in \R^n$.}
\end{equation*}
We denote by~$\meritm[k]$ the~$\ell_2$-merit function computed on the \gls{sqp} subproblem, i.e.,
\begin{equation}
    \label{eq:l2-merit-function-model}
    \meritm[k](\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma^k \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation}
where~$\Phi$ is defined by
\begin{equation}
    \label{eq:l2-merit-function-model-penalty}
    \Phi(d) \eqdef \sqrt{\sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2}.
\end{equation}
The framework is given in \cref{alg:derivative-free-trust-region-sqp}, which hides many details, including the definition of \enquote{convergence} in the loop, the calculation of~$\step[k]$, the update of~$\lm[k]$, and the geometry improvement of the interpolation set, which will be specified in \cref{subsec:managing-trust-region-radius,subsec:solving-trust-region-subproblem,subsec:least-squares-lagrange-multipliers,subsec:geometry-improvement}, respectively.

\begin{algorithm}
    \caption[Derivative-free trust-region \glsfmtshort{sqp} method]{Derivative-free trust-region \glsfmtshort{sqp} method\textsuperscript{$\dagger$}}
    \label{alg:derivative-free-trust-region-sqp}
    \DontPrintSemicolon
    \onehalfspacing
    \algorithmfootnote{\textsuperscript{$\dagger$}Recall that superscripts are iteration counters rather than exponents.}
    \KwData{Initial guess~$\iter[0] \in \R^n$, estimated Lagrange multiplier~$\lm[0] = [\lm[0]_i]_{i \in \iub \cup \ieq}^{\T}$, initial trust-region radius~$\rad[0] > 0$, and parameters~$0 < \eta_1 \le \eta_2 < 1$ and~$0 < \theta_1 < 1 < \theta_2$.}
    Set the penalty parameter~$\gamma^{-1} \gets  0$\;
    Build the initial interpolation set~$\xpt[0] \subseteq \R^n$ described in \cref{subsec:interpolation-based-quadratic-models}\;
    \For{$k = 0, 1, \dots$ until convergence}{
        Update~$\objm[k]$ and~$\conm[k]{i}$ for~$i \in \iub \cup \ieq$ as mentioned in \cref{subsec:interpolation-based-quadratic-models}\;
        Set the trial step~$\step[k] \in \R^n$ to an approximate solution to
        \begin{subequations}
            \label{eq:derivative-free-trust-region-sqp-subproblem}
            \begin{algomathalign}
                \min        & \quad \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
                \text{s.t.} & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step \le 0, ~ i \in \iub,\\
                            & \quad \conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                            & \quad \norm{\step} \le \rad[k],\\
                            & \quad \step \in \R^n, \nonumber
            \end{algomathalign}
        \end{subequations} \nllabel{alg:derivative-free-trust-region-sqp-subproblem}
        Pick a penalty parameter~$\gamma^k \ge \max @@ \set{\gamma^{k - 1}, \norm{\lm[k]}}$ providing~$\meritm[k](\step[k]) < \meritm[k](0)$ \nllabel{alg:derivative-free-trust-region-sqp-penalty}\;
        Evaluate the trust-region ratio
        \begin{algomathdisplay}
            \ratio[k] \gets \frac{\merit[k](\iter[k]) - \merit[k](\iter[k] + \step[k])}{\meritm[k](0) - \meritm[k](\step[k])}
        \end{algomathdisplay}
        \eIf{$\ratio[k] > 0$}{
            Choose a point~$\bar{y} \in \xpt[k]$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-1}
        }{
            Choose a point~$\bar{y} \in \xpt[k] \setminus \set{\iter[k]}$ to remove from~$\xpt[k]$\; \nllabel{alg:derivative-free-trust-region-sqp-remove-2}
        }
        Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k] \setminus \set{\bar{y}}) \cup \set{\iter[k] + \step[k]}$\;
        Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$\; \nllabel{alg:derivative-free-trust-region-sqp-iterate}
        Estimate the Lagrange multiplier~$\lm[k + 1] = [\lm[k + 1]_i]_{i \in \iub \cup \ieq}^{\T}$\; \nllabel{alg:derivative-free-trust-region-sqp-multipliers}
        Update the trust-region radius
        \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
            & \theta_1 \rad[k],  && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
            & \rad[k],           && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
            & \theta_2 \rad[k],  && \quad \text{otherwise}
        \end{algoempheq} \label{alg:derivative-free-trust-region-sqp-radius}
        Improve the geometry of~$\xpt[k + 1]$ if necessary\; \label{alg:derivative-free-trust-region-sqp-geometry}
    }
\end{algorithm}

In the implementation of \cref{alg:derivative-free-trust-region-sqp-iterate},~$\iter[k + 1]$ is always set to a best point in~$\xpt[k + 1]$ according to~$\merit[k]$, in the sense that it minimizes~$\merit[k]$ in~$\xpt[k + 1]$.
If~$\iter[k]$ turns out to be optimal in~$\xpt[k + 1]$ according to~$\merit[k]$, then we choose~$\iter[k + 1] = \iter[k]$, even if there are other optimal points.
Note however that we cannot naively set~$\iter[k + 1]$ to either~$\iter[k] + \step[k]$ if~$\ratio[k] > 0$, or~$\iter[k]$ otherwise.
This is because~$\iter[k]$ is a best point in~$\xpt[k]$ according to~$\merit[k - 1]$, but it may not be the best one according to~$\merit[k]$.

% In a practical implementation, the quadratic models on \cref{alg:derivative-free-trust-region-sqp-models} of \cref{alg:derivative-free-trust-region-sqp} are not computed from scratch, because only one point differs~$\xpt[k + 1]$ from~$\xpt[k]$.
% Details on this update mechanism are given in \cref{subsec:implementation-symmetric-broyden-update}.

\subsection{Solving the trust-region \glsfmtshort{sqp} subproblem}
\label{subsec:solving-trust-region-subproblem}

To solve the trust-region \gls{sqp} subproblem~\cref{eq:derivative-free-trust-region-sqp-subproblem}, we employ a Byrd-Omojokun approach.
It first generates a normal step as an approximate solution to
\begin{subequations}
    \label{eq:cobyqa-normal}
    \begin{align}
        \min        & \quad \sum_{i \in \iub} \posp{\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step}^2 + \sum_{i \in \ieq} [\conm[k]{i}(\iter[k]) + \nabla \conm[k]{i}(\iter[k])^{\T} \step]^2\\
        \text{s.t.} & \quad \xl \le \iter[k] + \step \le \xu,\\
                    & \quad \norm{\step} \le \zeta \rad[k], \label{eq:cobyqa-normal-tr}\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
for some~$\zeta \in (0, 1)$.
In the implementation, we choose~$\zeta = 0.8$.
If~$\iter[k]$ is feasible for the original problem~\cref{eq:problem-cobyqa}, we choose~$\nstep[k] = 0$.
Further, it generates a tangential step~$\tstep[k]$ by solving approximately
\begin{subequations}
    \label{eq:cobyqa-tangential-original}
    \begin{align}
        \min        & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.} & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max @@ \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub,\\
                    & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq,\\
                    & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                    & \quad \norm{\nstep[k] + \step} \le \rad[k],\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
and then sets the composite step~$\step[k] = \nstep[k] + \tstep[k]$.
Details on the calculations of the tangential and normal steps are provided in \cref{sec:cobyqa-tangential,sec:cobyqa-normal}, respectively.

If we have~$\iub \cup \ieq = \emptyset$, we then necessarily have~$\nstep[k] = 0$ because our algorithm guarantees that~$\xl \le \iter[k] \le \xu$.
The tangential subproblem is then identical to the original subproblem~\cref{eq:derivative-free-trust-region-sqp-subproblem}.
In \gls{cobyqa}, such a subproblem is approximately solved using the \gls{tcg} method that \citeauthor{Powell_2009} employed in \gls{bobyqa}~\cite{Powell_2009}.

When~$\iub \cup \ieq \neq \emptyset$, the tangential subproblem~\cref{eq:cobyqa-tangential-original} is approximately solved using the \gls{tcg} method that \citeauthor{Powell_2015} designed for \gls{lincoa}~\cite{Powell_2015}.
This method requires that
\begin{enumerate}
    \item the origin~$d = 0$ is feasible, and
    \item the trust region is centered on the origin.
\end{enumerate}
The first requirement is satisfied by~\cref{eq:cobyqa-tangential-original}.
To meet the second one, following the work of~\cite[Eq.~(2.10)]{Lalee_Nocedal_Plantenga_1998} and~\cite[Eq.~(15.4.3)]{Conn_Gould_Toint_2000}, we can solve instead
\begin{subequations}
    \label{eq:cobyqa-tangential}
    \begin{align}
        \min        & \quad [\nabla \objm[k](\iter[k]) + \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \nstep[k]]^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step\\
        \text{s.t.} & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step \le \max @@ \set{-\conm[k]{i}(\iter[k]) - \nabla \conm[k]{i}(\iter[k])^{\T} \nstep[k], 0}, ~ i \in \iub, \label{eq:cobyqa-tangential-ub}\\
                    & \quad \nabla \conm[k]{i}(\iter[k])^{\T} \step = 0, ~ i \in \ieq, \label{eq:cobyqa-tangential-eq}\\
                    & \quad \xl \le \iter[k] + \nstep[k] + \step \le \xu,\\
                    & \quad \norm{\step} \le \sqrt{(\rad[k])^2 - \norm{\nstep[k]}^2}, \label{eq:cobyqa-tangential-tr}\\
                    & \quad \step \in \R^n, \nonumber
    \end{align}
\end{subequations}
the only difference with~\cref{eq:cobyqa-tangential-original} being the trust-region constraint~\cref{eq:cobyqa-tangential-tr}.
In doing so, we would have
\begin{equation*}
    \norm{\step[k]} = \norm{\nstep[k] + \tstep[k]} \le \max_{d \in \R^n} @@ \set[\Big]{\norm{d} + \sqrt{(\rad[k])^2 - \norm{\step}^2} : \norm{d} \le \rad[k]} = \sqrt{2} \rad[k].
\end{equation*}
Therefore, to maintain the property~$\norm{\step[k]} \le \rad[k]$, we replace~$\rad[k]$ in the constraints~\cref{eq:cobyqa-normal-tr,eq:cobyqa-tangential-tr} with~$\rad[k] / \sqrt{2}$.
% Therefore, to maintain the property~$\norm{\step[k]} \le \rad[k]$, we replace the trust-region constraint of the tangential subproblem~\cref{eq:cobyqa-tangential-tr} with
% \begin{equation}
%     \label{eq:cobyqa-trust-region-radius}
%     \norm{\step} \le \sqrt{\frac{(\rad[k])^2}{2} - \norm{\nstep[k]}^2}.
% \end{equation}
% Of course, we must ensure that~$\norm{\nstep[k]} \le \rad[k] / \sqrt{2}$, so that the right-hand side in~\cref{eq:cobyqa-trust-region-radius} is well-defined.
% To do so, we select~$\zeta$ to satisfy~$\zeta \le 1 / \sqrt{2}$.
% To always provide some elbow room for the tangential step, we restrict the previous condition to~$\zeta < 1 / \sqrt{2}$, and we finally choose for \gls{cobyqa}
% \begin{equation*}
%     \zeta = \frac{2 \sqrt{2}}{5}.
% \end{equation*}

% Theoretically, it is possible to evaluate the composite step directly.
% However, the methods used to solve the subproblems usually require the trust-region center to be feasible, which is not the case for the composite subproblem.
% Therefore, we modify the tangential subproblem to make the origin the trust-region center, which is then feasible.
% Therefore, we build explicitely the tangential step.
% See Trust-Region Methods, p.~660.

\subsection{Least-squares Lagrange multiplier}
\label{subsec:least-squares-lagrange-multipliers}

We now introduce the strategy employed by \gls{cobyqa} to estimate the Lagrange multiplier on \cref{alg:derivative-free-trust-region-sqp-multipliers} of \cref{alg:derivative-free-trust-region-sqp}.

% Recall that the \gls{sqp} method can be regarded as an approximate Newton method applied to the \gls{kkt} system.
Similar to~\cite[\S~15.2, p.~626]{Conn_Gould_Toint_2000} and~\cite[Eq.~(18.22)]{Nocedal_Wright_2006}, we let~$\lm[k + 1]$ be a \emph{least-squares Lagrange multiplier} (see also~\cite[\S~3.3]{Dussault_1995}), i.e., a solution to
% It is natural to set the estimated Lagrange multiplier~$\lm[k + 1]$ to the one that attempts to satisfy the \gls{kkt} conditions as much as possible using the information available so far.
\begin{subequations}
    \label{eq:least-squares-lagrange-multipliers-cobyqa}
    \begin{align}
        \min_{\lm}  & \quad \norm[\bigg]{\nabla \objm[k](\iter[k]) + \sum_{i \in \iub \cup \ieq} \lm_i \nabla \conm[k]{i}(\iter[k])}\\
        \text{s.t.} & \quad \lm_i = 0, ~ i \in \set{j \in \iub : \conm[k]{j}(\iter[k]) < 0} \label{eq:least-squares-lagrange-multipliers-cobyqa-complementary-slackness}\\
                    & \quad \lm_i \ge 0, ~ i \in \iub,
    \end{align}
\end{subequations}
where~$\lm = [\lm_i]_{i \in \iub \cup \ieq}^{\T}$.
Note that for all~$i \in \iub$,~$\conm[k]{i}(\iter[k]) = \con{i}(\iter[k])$, because~$\conm[k]{i}$ interpolates~$\con{i}$ on~$\xpt[k]$ and~$\iter[k] \in \xpt[k]$.
The conditions~\cref{eq:least-squares-lagrange-multipliers-cobyqa-complementary-slackness} correspond to the complementary slackness conditions of the inactive constraints at~$\iter[k]$.
Even though the complementary slackness conditions at the solution are~$\lm[\ast]_i \con{i}(\iter[\ast]) = 0$ for~$i \in \iub$, it is unreasonable to force~$\lm_i^{k + 1} = 0$ if~$\con{i}(\iter[k]) > 0$ and~$i \in \iub$, because the corresponding constraint is currently active.
% This problem can be easily simplified as follows.
% For all indices~$i \in \iub$ such that~$\conm[k]{i}(\iter[k]) \neq 0$, we necessarily have~$\lm[k + 1]_i = 0$.
% Therefore, the linear constraints~\cref{eq:least-squares-lagrange-multipliers-cobyqa-complementary-slackness} can be removed from the problem by considering only the indices in
% \begin{equation*}
%     \ieq \cup \set{i \in \iub : \conm[k]{i}(\iter[k]) \ge 0},
% \end{equation*}
% and by setting the remaining components of the least-squares Lagrange multiplier to zero.
% Another possibility, leading to a slightly different problem, is to consider only the indices in
% \begin{equation*}
%     \ieq \cup \set{i \in \iub : \conm[k]{i}(\iter[k + 1]) \le 0},
% \end{equation*}
% and to set the remaining components of the least-squares Lagrange multiplier to zero.
% This is the method employed by \gls{cobyqa}.
Details on the calculations of the least-squares Lagrange multiplier are provided in \cref{sec:cobyqa-lagrange-multipliers}.

We also mention that the least-squares multiplier can be regarded as an approximation of the multiplier of the \gls{sqp} subproblem, known as the QP multiplier.
See~\cite[pp.~538--539]{Nocedal_Wright_2006} for more details.

\subsection{Managing the trust-region radius}
\label{subsec:managing-trust-region-radius}

Inspired by the performance of \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa} (see \cref{subsec:uobyqa,subsec:newuoa-bobyqa-lincoa}), we employ their trust-region radius management strategy in \gls{cobyqa}, in place of \cref{alg:derivative-free-trust-region-sqp-radius} of \cref{alg:derivative-free-trust-region-sqp}.
It consists in maintaining both the trust-region radius~$\rad[k]$ and a lower bound~$\radlb[k]$ of it.

The update of~$\rad[k]$ is given in \cref{alg:update-trust-region-radius}, which is typical for trust-region methods, except that the lower bound~$\radlb[k]$ is imposed.
The idea behind~$\radlb[k]$ will be explained later.
The parameters chosen in \gls{cobyqa} are~$\eta_1 = 0.1$,~$\eta_2 = 0.7$,~$\theta_1 = 0.5$,~$\theta_2 = 1.4$,~$\theta_3 = \sqrt{2}$, and~$\theta_4 = 2$.
Note that it is crucial to ensure that~$\theta_2 < \theta_3$.
Otherwise, if~$\rad[k] = \radlb[k]$ and the trial step~$\step[k]$ performs very well (i.e.,~$\ratio[k] > \eta_2$), then the method would set~$\rad[k + 1] = \rad[k]$, but~$\rad[k + 1] > \rad[k]$ is expected if~$\norm{\step[k]}$ is close to~$\rad[k]$.

\begin{algorithm}
    \caption{Updating the trust-region radius}
    \label{alg:update-trust-region-radius}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Current lower bound on the trust-region radius~$\radlb[k] > 0$, current trust-region radius~$\rad[k] \ge \radlb[k]$, current trust-region ratio~$\ratio[k] \in \R$, current trial step~$\step[k] \in \R^n$, and parameters~$0 < \eta_1 \le \eta_2 < 1$, and~$0 < \theta_1 < 1 \le \theta_2 < \theta_3 < \theta_4$.}
    \KwResult{Updated trust-region radius~$\rad[k + 1]$.}
    Update the trust-region radius
    \begin{algoempheq}[left={\rad[k + 1] \gets \empheqlbrace}]{alignat*=2}
        & \theta_1 \rad[k]                                                                      && \quad \text{if~$\ratio[k] \le \eta_1$,}\\
        & \max @@ \set{\theta_1 \rad[k], \norm{\step[k]}}                                          && \quad \text{if~$\eta_1 < \ratio[k] \le \eta_2$,}\\
        & \min @@ \set{\theta_3 \rad[k], \max @@ \set{\theta_1 \rad[k], \theta_4 \norm{\step[k]}}}    && \quad \text{otherwise}
    \end{algoempheq}
    \If{$\rad[k + 1] \le \theta_2 \radlb[k]$}{
        $\rad[k + 1] \gets \radlb[k]$\;
    }
\end{algorithm}

The value of~$\radlb[k]$ can be regarded as an indicator of the resolution of the algorithm.
If we do not impose~$\rad[k] \ge \radlb[k]$, the trust-region radius~$\rad[k]$ may be reduced to a value that is too small for the current precision of the algorithm, making the interpolation points concentrating too much.
The value of~$\radlb[k]$ is never increased, and is decreased when the algorithm decides that the work for the current value of~$\radlb[k]$ is finished.
This is reflected in practice by
\begin{enumerate}
    \item the fact that~$\rad[k]$ reaches its lower bound~$\radlb[k]$,
    \item a poor performance of the trust-region trial step~$\step[k]$, and
    \item the fact that the interpolation points are all close enough to~$\iter[k + 1]$.
\end{enumerate}
More specifically, similar to Powell's solvers, \gls{cobyqa} reduces the value of~$\radlb[k]$ if
\begin{equation*}
    \radlb[k] = \rad[k], \quad \ratio[k] \le \eta_1, \quad \text{and} \quad \max_{y \in \xpt[k + 1]} @@ \norm{y  - \iter[k + 1]} \le 2 \radlb[k].
\end{equation*}
There is also another exceptional case where~$\radlb[k]$ is reduced, which will be detailed at the end of \cref{subsec:geometry-improvement}.
\Cref{alg:reducing-lower-bound-trust-region-radius} presents the method employed by \gls{cobyqa} to reduce~$\radlb[k]$ in such a case.
The parameters chosen in \gls{cobyqa} are~$\eta_3 = 16$,~$\eta_4 = 250$, and~$\theta_5 = 0.1$.
The algorithm and the parameters are identical to those of \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, \gls{bobyqa}~\cite{Powell_2009}, and \gls{lincoa}.

\begin{algorithm}
    \caption{Reducing the lower bound on the trust-region radius}
    \label{alg:reducing-lower-bound-trust-region-radius}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Final trust-region radius~$\radlb[\infty] > 0$, current lower bound on the trust-region radius~$\radlb[k] \ge \radlb[\infty]$, updated trust-region radius~$\rad[k + 1] \ge \radlb[k]$, and parameters~$1 \le \eta_3 < \eta_4$ and~$0 < \theta_5 < 1$.}
    \KwResult{Reduced lower bound on trust-region radius~$\radlb[k + 1]$ and modified trust-region radius~$\rad[k + 1]$.}
    \eIf{$\radlb[k] = \radlb[\infty]$}{
        Terminate the optimization method\; \nllabel{alg:reducing-lower-bound-trust-region-radius-stop}
    }{
        Update the lower bound on the trust-region radius
        \begin{algoempheq}[left={\radlb[k + 1] \gets \empheqlbrace}]{alignat*=2}
            & \theta_5 \radlb[k]                && \quad \text{if~$\eta_4 < \radlb[k] / \radlb[\infty]$,}\\
            & \sqrt{\radlb[k] \radlb[\infty]}   && \quad \text{if~$\eta_3 < \radlb[k] / \radlb[\infty] \le \eta_4$,}\\
            & \radlb[\infty]                    && \quad \text{otherwise}
        \end{algoempheq}
        Update the trust-region radius~$\rad[k + 1] \gets \max @@ \set{\rad[k + 1], \radlb[k + 1]}$\;
    }
\end{algorithm}

If \cref{alg:reducing-lower-bound-trust-region-radius-stop} of \cref{alg:reducing-lower-bound-trust-region-radius} is reached, then the algorithm has finished the work for the smallest desired resolution and hence, we stop the computations.
This is in fact the definition of \enquote{convergence} we mentioned in \cref{alg:derivative-free-trust-region-sqp}, which is also the stopping criterion used in the Powell's solvers.

\subsection{Updating the interpolation set}

We now detail how \gls{cobyqa} updates the interpolation set~$\xpt[k]$.
To this end, we only need to detail the choice of~$\bar{y}$ in \cref{alg:derivative-free-trust-region-sqp-remove-1,alg:derivative-free-trust-region-sqp-remove-2} of \cref{alg:derivative-free-trust-region-sqp}.
Then,~$\xpt[k + 1]$ will be set to~$(\xpt[k] \setminus \set{\bar{y}}) \cup \set{\iter[k] + \step[k]}$.

Let us first consider the case~$\ratio[k] \ge 0$, so that~$\bar{y}$ is chosen from~$\xpt[k]$.
We denote by~$\bar{\iter}$ the closest point from~$\iter[k]$ that solves
\begin{equation*}
    \min_{y \in \xpt[k]} @@ \merit[k](y).
\end{equation*}
This point is not necessarily~$\iter[k]$, because~$\merit[k]$ may differ from~$\merit[k - 1]$ due to the update of the penalty parameter.
If several such points exist, we select any of them.
We then set~$\bar{y}$ to a solution to
\begin{equation}
    \label{eq:choice-point-to-remove-trust-region}
    \max_{y \in \xpt[k]} @@ \abs{\omega(y)} \norm{y - \bar{\iter}}^4,
\end{equation}
where~$\omega(y)$ is a scaling factor, detailed later.
The term~$\norm{y - \bar{\iter}}$ in~\cref{eq:choice-point-to-remove-trust-region} intends to set~$\bar{y}$ to a point far away from~$\bar{\iter}$, because the interpolation points must be reasonably close in order to achieve a good precision of the models.
% Further, \gls{dfo} methods usually set~$\bar{y}$ to be a solution to
% \begin{equation*}
%     \max_{y \in \xpt[k]} \norm{y - \bar{\iter}}.
% \end{equation*}
To explain the scalar factor~$\omega(y)$, recall from \cref{subsec:implementation-symmetric-broyden-update} that the inverse of the coefficient matrix of the interpolation problem is maintained.
Whenever an interpolation point is replaced with a new one, this inverse will be updated by the formula detailed in~\cite[Eq.~(2.12)]{Powell_2004c}, which has a scalar denominator.
We set~$\omega(y)$ to this denominator corresponding to the replacement of~$y \in \xpt[k]$ with~$\iter[k] + \step[k]$.
This is because we want this denominator to be far away from zero to avoid numerical difficulties.
The choice of the formula~\cref{eq:choice-point-to-remove-trust-region} is taken from \gls{lincoa}, the most recent \gls{dfo} solver of \citeauthor{Powell_2015}.
He also made very similar choices for \gls{newuoa}~\cite[Eq.~(7.4)]{Powell_2006} and \gls{bobyqa}~\cite[Eq.~(6.1)]{Powell_2009}.

The strategy for the case~$\ratio[k] < 0$ is quite similar.
We set~$\bar{y}$ to a solution to
\begin{equation*}
    \max_{y \in \xpt[k] \setminus \set{\iter[k]}} @@ \abs{\omega(y)} \norm{y - \bar{\iter}}^4.
\end{equation*}
This case enforces~$\bar{y} \neq \iter[k]$ to avoid removing~$\iter[k]$ from~$\xpt[k]$, as this point is better than~$\iter[k] + \step[k]$ according to~$\merit[k - 1]$.

Theoretically, it is tempting to set~$\bar{y}$ to the point that optimizes the~$\Lambda$-poisedness (see \cref{subsec:symmetric-broyden-updates}) of~$\xpt[k + 1]$ in some set, say
\begin{equation}
    \label{eq:ball-lambda-poisedness}
    \set{x \in \R^n : \norm{x - \bar{\iter}} \le \radlb[k]}.
\end{equation}
This idea has however a major drawback: it is expensive to implement due to the definition of the~$\Lambda$-poisedness.
Hence, from a computational perspective, we decide not employ this technique in \gls{cobyqa}.

\subsection{Geometry of the interpolation set}
\label{subsec:geometry-improvement}

In this section, we detail the geometry-improving procedure of \gls{cobyqa}, corresponding to \cref{alg:derivative-free-trust-region-sqp-geometry} of \cref{alg:derivative-free-trust-region-sqp}.
As we mentioned in \cref{ch:interpolation}, the interpolation set has to be reasonably well-poised to ensure the accuracy of the interpolation models.
% As we mentioned in \cref{ch:interpolation}, the interpolation set~$\xpt[k]$ is adequate only if it is poised, i.e., only if the interpolation problem admits a solution for any function that is interpolated.
% Moreover, we may wish that~$\xpt[k]$ is~$\Lambda$-poised in
% \begin{equation*}
%     \set{\iter \in \R^n : \norm{x - \iter[k]} \le \radlb[k]},
% \end{equation*}
% for some reasonably low~$\Lambda$, because the purpose of~$\radlb[k]$ is to maintain adequate distance between the interpolation points.
% However, \cref{alg:derivative-free-trust-region-sqp} never ensures that such properties hold.
However, it is known that model-based \gls{dfo} methods tend to lose the poisedness of their interpolation set as the iterations progress.
To cope with this difficulty, such methods usually include a geometry-improving mechanism.
This topic is well studied, see for example~\cite{Conn_Scheinberg_Vicente_2008a,Conn_Scheinberg_Vicente_2008b,Fasano_Morales_Nocedal_2009,Scheinberg_Toint_2010}.

We adopt a geometry-improving strategy designed by \citeauthor{Powell_2009} for \gls{bobyqa}~\cite{Powell_2009}.
% Some trust-region iterations are replaced with a geometry-improving iteration.
A point~$\bar{y} \in \xpt[k + 1]$ is chosen to be replaced by another one~$\iter[k + 1] + \rstep[k + 1]$, where the \emph{restoration step}~$\rstep[k + 1] \in \R^n$ is chosen to improve the geometry of~$\xpt[k + 1]$.

First of all, the point~$\bar{y}$ is chosen to be a solution to
\begin{equation}
    \label{eq:choice-point-geometry-improving}
    \max_{y \in \xpt[k + 1]} \norm{y - \iter[k + 1]}.
\end{equation}
Further, similar to~\cite[Eq.~(6.6)]{Powell_2006}, we let~$\rstep[k + 1] \in \R^n$ be an approximate solution to
\begin{subequations}
    \label{eq:geometry-subproblem}
    \begin{align}
        \max        & \quad \abs{\lagp[\bar{y}](\iter[k + 1] + \step)}\\
        \text{s.t.} & \quad \xl \le \iter[k + 1] + \step \le \xu,\\
                    & \quad \norm{\step} \le \bar{\rad},\\
                    & \quad \step \in \R^n,
    \end{align}
\end{subequations}
where~$\lagp[\bar{y}]$ denotes the minimum Frobenius norm Lagrange polynomials for~$\xpt[k + 1]$ associated with~$\bar{y}$ (see \cref{def:lagrange-polynomials-minimum-norm}).
As in \gls{lincoa}, we set~$\bar{\rad} = \max \set{\rad[k + 1] / 10, \radlb[k + 1]}$.
We will detail how to solve~\cref{eq:geometry-subproblem} in \cref{sec:cobyqa-geometry-improving}.

The reason for choosing such an objective function is as follows.
Recall that we need to update the inverse of the coefficient matrix of the interpolation problem to replace~$\bar{y}$ with~$\iter[k + 1] + \rstep[k + 1]$ in~$\xpt[k + 1]$.
As already mentioned, the updating formula has a scalar denominator.
This denominator is always lower bounded by~$\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])^2$ as shown in~\cite[Eq.~(6.5)]{Powell_2006}.
Therefore, by selecting the restoration step~$\rstep[k + 1]$ to maximize~$\abs{\lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1])}$, we keep the denominator away from zero, avoiding numerical difficulties.
% Second of all, denote by~$B$ and~$\widetilde{B}$ the coefficient matrices of the interpolation problems on the original and the modified sets~$\xpt[k + 1]$, respectively.
% \Citeauthor{Powell_2001}~\cite[\S~2]{Powell_2001} showed that
% \begin{equation*}
%     \lagp[\bar{y}](\iter[k + 1] + \rstep[k + 1]) = \frac{\det \widetilde{B}}{\det B}.
% \end{equation*}
% This property also encourages us to let the restoration step~$\rstep[k + 1]$ solve~\cref{eq:geometry-subproblem}.

Now that the general framework of the geometry-improving phase is set up, we need to decide when to entertain such a mechanism.
It is trigerred when
\begin{enumerate}
    \item the trust-region trial step~$\step[k]$ performed poorly, and
    \item some interpolation points are far away from~$\iter[k + 1]$.
\end{enumerate}
More specifically, \gls{cobyqa} modifies the interpolation set~$\xpt[k + 1]$ if
\begin{equation*}
    \ratio[k] \le \eta_1 \quad \text{and} \quad \max_{y \in \xpt[k + 1]} @@ \norm{y - \iter[k + 1]} \ge \max @@ \set{\rad[k + 1], 2 \radlb[k + 1]}.
\end{equation*}
When this condition holds, \gls{cobyqa} entertains the geometry-improving phase given in \cref{alg:geometry-improving}.

\begin{algorithm}
    \caption{Geometry-improving phase}
    \label{alg:geometry-improving}
    \DontPrintSemicolon
    \onehalfspacing
    \KwData{Bounds~$\xl$ and~$\xu$, current interpolation set~$\xpt[k + 1] \subseteq \R^n$, and current best point so far~$\iter[k + 1] \in \xpt[k + 1]$.}
    \KwResult{Updated interpolation set~$\xpt[k + 1]$ and updated iterate~$\iter[k + 1]$.}
    Set~$\bar{y}$ to be a solution to~\cref{eq:choice-point-geometry-improving}\;
    Set the step~$\rstep[k + 1] \in \R^n$ to be an approximate solution to~\cref{eq:geometry-subproblem}\;
    Update the interpolation set~$\xpt[k + 1] \gets (\xpt[k + 1] \setminus \set{\bar{y}}) \cup \set{\iter[k + 1] + \rstep[k + 1]}$\;
    Update the current iterate~$\iter[k + 1]$ to a solution to~$\min_{y \in \xpt[k + 1]} \merit[k](y)$ \label{alg:geometry-improving-iterate}\;
\end{algorithm}

There is an exceptional case where we jump from \cref{alg:derivative-free-trust-region-sqp-subproblem} to \cref{alg:derivative-free-trust-region-sqp-geometry}, after setting the values~$\gamma^k = \gamma^{k - 1}$,~$\xpt[k + 1] = \xpt[k]$,~$\iter[k + 1] = \iter[k]$, and~$\lm[k + 1] = \lm[k]$.
\Cref{alg:derivative-free-trust-region-sqp} omits this case for simplicity, and we detail it now.
This jump is done if the trust-region trial step~$\step[k]$ generated at \cref{alg:derivative-free-trust-region-sqp-subproblem} of \cref{alg:derivative-free-trust-region-sqp} is small compared to the current trust-region radius, more precisely, if~$\norm{\step[k]} < \rad[k] / 2$.
In this case, we first reduce~$\rad[k + 1]$ to~$\rad[k + 1] / 2$, setting it further to~$\radlb[k]$ if this reduced value is below~$\theta_2 \radlb[k]$.
We then invoke \cref{alg:geometry-improving} if
\begin{equation*}
    \max_{y \in \xpt[k + 1]} @@ \norm{y - \iter[k + 1]} \ge \rad[k + 1].
\end{equation*}
However, if~$\norm{\step[k]} < \rad[k] / 2$ has happened at five consective iterations, or~$\norm{\step[k]} < \rad[k] / 10$ at three consecutive iterations, then the geometry-improving phase is not invoked.
Instead, we decrease~$\radlb[k]$ by invoking \cref{alg:reducing-lower-bound-trust-region-radius}, and continue with the next trust-region iteration.
This mechanism has been developed by Powell in his solver \gls{lincoa}, and similar strategies exist in \gls{uobyqa}~\cite{Powell_2002}, \gls{newuoa}~\cite{Powell_2006}, and \gls{bobyqa}~\cite{Powell_2009}.

\section{Management of bound and linear constraints}
\label{sec:simple-constraints}

The implementation of \gls{cobyqa} accepts three types of constraints, namely bound constraints, linear constraints, and nonlinear constraints.
From a theoretical standpoint, problems written in the form
\begin{align*}
    \min        & \quad \obj(\iter)\\
    \text{s.t.} & \quad \con{i}(\iter) \le 0, ~ i \in \iub,\\
                & \quad \con{i}(\iter) = 0, ~ i \in \ieq,\\
                & \quad \iter \in \R^n,
\end{align*}
may have bound and linear constraints included in the constraints~$\set{\con{i}}_{i \in \iub \cup \ieq}$.
However, our implementation handles these types of constraints separately, for the following reasons.

% First of all, note that in the general form of nonlinearly-constrained problems~\cref{eq:problem-cobyqa}, we did not include the bound constraints~\cref{eq:problem-cobyqa-bd} in the inequality constraints~\cref{eq:problem-cobyqa-ub}.
First of all, bound constraints often represent inalienable physical or theoretical restrictions.
In many applications for which \gls{cobyqa} is designed, the objective function~\cref{eq:problem-cobyqa-obj} is not defined if the bounds~\cref{eq:problem-cobyqa-bd} are violated.
% For instance, the tuning of nonlinear optimization methods (see \cref{subsec:tuning-nonlinear-optimization-methods}) involves bounds that cannot be violated, as the optimization methods that are tuned may not be defined otherwise.
For an example, see the hyperparameter tuning problem given in \cref{subsec:machine-learning}.
For this reason, every point that \gls{cobyqa} encounters always respects these bounds, as is also the case for the \gls{bobyqa} method, presented in \cref{subsec:newuoa-bobyqa-lincoa}.
% When establishing the problem~\cref{eq:problem-cobyqa}, we assumed that~$\xl < \xu$.
% Note that this requirement is weak, as otherwise, the problem~\cref{eq:problem-cobyqa} would be either infeasible, or admit fix variables.
% Thus, note also that they are very simple constraints.
% It is, for example, trivial to check whether a point is feasible with respect to the bound constraints~\cref{eq:problem-cobyqa-bd}, and easy to project any point onto the bound constraints.
Therefore, \gls{cobyqa} handles bound constraints separately.
% This is another reason why \gls{cobyqa} handles them separately.

The linear constraints are usually much less restrictive.
In applications, the objective function is often well-defined even at points that are infeasible with respect to the linear constraints.
Therefore, we do not enforce \gls{cobyqa} to always respect the linear constraints.
However, when evaluating a model~$\conm[k]{i}$ of a linear constraint~$\con{i}$, we enforce~$\conm[k]{i} \equiv \con{i}$.
This reduces the computational complexity of evaluating all the models, and it also suppresses all damages that could be generated by computer rounding errors.

\section{Merit function and update of the penalty parameters}

We now discuss the merit function we use in \gls{cobyqa}.
Recall that we decided to use the~$\ell_2$-merit function.
This is because the~$\ell_2$-merit function~$\meritm[k]$ computed on the \gls{sqp} subproblem, given in~\cref{eq:l2-merit-function-model}, satisfy \cref{prop:byrd-omojokun-penalty}.
In what follows, we denote by~$\meritm_{\gamma}$ the~$\ell_2$ merit function evaluated on the \gls{sqp} subproblem, i.e.,
\begin{equation*}
    \meritm_{\gamma}(\step) \eqdef \nabla \objm[k](\iter[k])^{\T} \step + \frac{1}{2} \step^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step + \gamma \Phi(\step), \quad \text{for~$\step \in \R^n$,}
\end{equation*}
where~$\Phi$ is defined by~\cref{eq:l2-merit-function-model-penalty} and where~$\gamma$ is the corresponding penalty parameter.
Note that we did not include the bound constraints in the definition of the merit function, because the points visited by \gls{cobyqa} always satisfy the bound constraints~\cref{eq:problem-cobyqa-bd}.

\begin{proposition}
    \label{prop:byrd-omojokun-penalty}
    Given a composite step~$\step[k] = \nstep[k] + \tstep[k]$ generated by the Byrd-Omojokun approach, there exists~$\bar{\gamma} \ge 0$ such that for all~$\gamma \ge \bar{\gamma}$, we have~$\meritm_{\gamma}(\step[k]) \le \meritm_{\gamma}(0)$.
    Moreover, the least possible such value is
    \begin{empheq}[left={\bar{\gamma} = \empheqlbrace}]{alignat*=2}
        & 0                                                                                                                                                                         && \quad \text{if~$\Phi(\step[k]) = \Phi(0)$,}\\
        & \posp[\bigg]{\frac{\nabla \objm[k](\iter[k])^{\T} \step[k] + (\step[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \step[k] / 2}{\Phi(0) - \Phi(\step[k])}}  && \quad \text{otherwise.}
    \end{empheq}
\end{proposition}

\begin{proof}
    Since~$\nstep[k]$ solves~\cref{eq:cobyqa-normal}, we have~$\Phi(\nstep[k]) \le \Phi(0)$.
    Moreover, since~$\tstep[k]$ satisfies~\cref{eq:cobyqa-tangential-ub,eq:cobyqa-tangential-eq}, we have~$\Phi(\nstep[k] + \tstep[k]) \le \Phi(\nstep[k])$ so that~$\Phi(\step[k]) \le \Phi(0)$.
    If~$\Phi(\step[k]) = \Phi(0)$, then~$\Phi(\nstep[k]) = \Phi(0)$ and hence,~$\nstep[k] = 0$ because~$\nstep[k]$ is the least-norm solution to~\cref{eq:cobyqa-normal}.
    In such a case, the result is clear, because the tangential step satisfies
    \begin{equation*}
        \nabla \objm[k](\iter[k])^{\T} \tstep[k] + \frac{1}{2} (\tstep[k])^{\T} \nabla_{x, x}^2 \lagm[k](\iter[k], \lm[k]) \tstep[k]  \le 0.
    \end{equation*}
    Otherwise, if~$\Phi(\step[k]) < \Phi(0)$, the result is clear because~$\meritm_{\gamma}$ is linear with respect to~$\gamma$.
\end{proof}

The strategy of \gls{cobyqa} to increase the penalty parameter is given in \cref{alg:increase-penalty}.
Note that this strategy is well-defined, because of \cref{prop:byrd-omojokun-penalty}.
However, since we impose on \cref{alg:derivative-free-trust-region-sqp-penalty} of \cref{alg:derivative-free-trust-region-sqp} that~$\gamma^k \ge \gamma^{k - 1}$, the penalty parameter may become huge, which may lead to computational difficulties.
Therefore, we modify \cref{alg:derivative-free-trust-region-sqp} to include a mechanism proposed by \citeauthor{Powell_1994} in his solver \gls{cobyla}~\cite{Powell_1994}.
It consists in reducing~$\gamma^k$ whenever~$\radlb[k]$ is decreased.
The exact mechanism exmployed by \gls{cobyqa} is given in \cref{alg:reducting-penalty}.
For simplicity, we assume that~$\ieq = \emptyset$.
If~$\ieq \neq \emptyset$, \gls{cobyqa} will view each equality constraint as two inequality constraints when invoking \cref{alg:reducting-penalty}.

\begin{algorithm}
    \caption[Reducing the penalty parameter]{Reducing the penalty parameter\textsuperscript{$\ddagger$}}
    \label{alg:reducting-penalty}
    \DontPrintSemicolon
    \onehalfspacing
    \algorithmfootnote{\textsuperscript{$\ddagger$}We assume that~$\ieq = \emptyset$; otherwise, each equality constraint is viewed as two inequality constraints.}
    \KwData{Current interpolation set~$\xpt[k + 1] \subseteq \R^n$ and current penalty parameter~$\gamma^k \ge 0$.}
    \KwResult{Modified penalty parameter~$\gamma^k \ge 0$.}
    Set indices of the important constraints
    \begin{algomathdisplay}
        \iub^{\ast} \eqdef \set[\big]{i \in \iub : \min_{y \in \xpt[k + 1]} @@ \con{i}(y) < \max_{y \in \xpt[k + 1]} @@ 2 \con{i}(y)}
    \end{algomathdisplay}
    \eIf{$\mathcal{K} = \emptyset$}{
        Set~$\gamma^k \gets 0$\;
    }{
        Replace~$\gamma^k$ by
        \begin{algomathdisplay}
            \min @@ \set[\bigg]{\frac{\max_{y \in \xpt[k + 1]} @@ \obj(y) - \min_{y \in \xpt[k + 1]} @@ \obj(y)}{\min_{i \in \iub^{\ast}} @@ \{ \max_{y \in \xpt[k + 1]} @@ \con{i}(y) - \min_{y \in \xpt[k + 1]} @@ \negp{\con{i}(y)} \}}, \gamma^k}
        \end{algomathdisplay} \label{alg:reducting-penalty-replace}
    }
\end{algorithm}
\nomenclature[Ob]{$\negp{\cdot}$}{Negative-part operator}%

The notation~$\negp{\cdot}$ in \cref{alg:reducting-penalty-replace} of \cref{alg:reducting-penalty} takes the negative part of a given number.
The term in \cref{alg:reducting-penalty-replace} is explained in~\cite[\S~4]{Powell_1994}.
Its numerator corresponds to a typical change in the objective function, while the denominator's term
\begin{equation*}
    \max_{y \in \xpt[k + 1]} @@ \con{i}(y) - \min_{y \in \xpt[k + 1]} @@ \negp{\con{i}(y)}
\end{equation*}
represents a typical change in the~$i$th constraint if~$\min_{y \in \xpt[k + 1]} \con{i}(y) \le 0$, and some distance to feasibility otherwise.
Of course, this term is very empirical, and other choices could be made.
This concludes the general description of \gls{cobyqa}.

% \section{Summary of the method}

% We present in this section a summary of the method employed by \gls{cobyqa}.
